{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, MaxPooling2D \n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt #Â used for visualisation \n",
    "import pandas as pd #used to turn model history into a dataframe which we can manipulate and plot with\n",
    "import time #used to compute code run time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n",
      "Final Train matrix shape (60000, 784)\n",
      "Final Test matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "# Setup train and test splits\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# printing the shape before reshaping and normalizing the data\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "\n",
    "# Reshape the data from a 3d tensor into a 2d tensor\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "# print the final input shape ready for training\n",
    "print(\"Final Train matrix shape\", X_train.shape)\n",
    "print(\"Final Test matrix shape\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding labels using keras \n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Investigating effect of Epoch size on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.2809 - accuracy: 0.6992 - val_loss: 0.8108 - val_accuracy: 0.8331\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7159 - accuracy: 0.8415 - val_loss: 0.6064 - val_accuracy: 0.8619\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5867 - accuracy: 0.8592 - val_loss: 0.5246 - val_accuracy: 0.8771\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5250 - accuracy: 0.8697 - val_loss: 0.4793 - val_accuracy: 0.8842\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4877 - accuracy: 0.8762 - val_loss: 0.4496 - val_accuracy: 0.8896\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4619 - accuracy: 0.8805 - val_loss: 0.4287 - val_accuracy: 0.8927\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4429 - accuracy: 0.8839 - val_loss: 0.4127 - val_accuracy: 0.8945\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4281 - accuracy: 0.8865 - val_loss: 0.3999 - val_accuracy: 0.8969\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4162 - accuracy: 0.8886 - val_loss: 0.3896 - val_accuracy: 0.8984\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4062 - accuracy: 0.8910 - val_loss: 0.3811 - val_accuracy: 0.8999\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3978 - accuracy: 0.8929 - val_loss: 0.3743 - val_accuracy: 0.9021\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3906 - accuracy: 0.8939 - val_loss: 0.3678 - val_accuracy: 0.9029\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3843 - accuracy: 0.8952 - val_loss: 0.3621 - val_accuracy: 0.9035\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3786 - accuracy: 0.8964 - val_loss: 0.3575 - val_accuracy: 0.9051\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3737 - accuracy: 0.8975 - val_loss: 0.3528 - val_accuracy: 0.9052\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3691 - accuracy: 0.8985 - val_loss: 0.3490 - val_accuracy: 0.9063\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3650 - accuracy: 0.8991 - val_loss: 0.3454 - val_accuracy: 0.9069\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3613 - accuracy: 0.9001 - val_loss: 0.3423 - val_accuracy: 0.9086\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3579 - accuracy: 0.9009 - val_loss: 0.3394 - val_accuracy: 0.9083\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3547 - accuracy: 0.9018 - val_loss: 0.3367 - val_accuracy: 0.9095\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3518 - accuracy: 0.9023 - val_loss: 0.3342 - val_accuracy: 0.9096\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3491 - accuracy: 0.9032 - val_loss: 0.3320 - val_accuracy: 0.9095\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3465 - accuracy: 0.9037 - val_loss: 0.3299 - val_accuracy: 0.9101\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3442 - accuracy: 0.9043 - val_loss: 0.3277 - val_accuracy: 0.9118\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3419 - accuracy: 0.9048 - val_loss: 0.3255 - val_accuracy: 0.9105\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3398 - accuracy: 0.9056 - val_loss: 0.3238 - val_accuracy: 0.9116\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3378 - accuracy: 0.9059 - val_loss: 0.3219 - val_accuracy: 0.9114\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3360 - accuracy: 0.9065 - val_loss: 0.3208 - val_accuracy: 0.9116\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3342 - accuracy: 0.9070 - val_loss: 0.3189 - val_accuracy: 0.9127\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3325 - accuracy: 0.9075 - val_loss: 0.3177 - val_accuracy: 0.9127\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3309 - accuracy: 0.9081 - val_loss: 0.3164 - val_accuracy: 0.9132\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3294 - accuracy: 0.9087 - val_loss: 0.3152 - val_accuracy: 0.9138\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3279 - accuracy: 0.9089 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3265 - accuracy: 0.9092 - val_loss: 0.3130 - val_accuracy: 0.9145\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3252 - accuracy: 0.9093 - val_loss: 0.3120 - val_accuracy: 0.9146\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3239 - accuracy: 0.9100 - val_loss: 0.3106 - val_accuracy: 0.9151\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3227 - accuracy: 0.9101 - val_loss: 0.3096 - val_accuracy: 0.9151\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3215 - accuracy: 0.9106 - val_loss: 0.3086 - val_accuracy: 0.9160\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3203 - accuracy: 0.9108 - val_loss: 0.3078 - val_accuracy: 0.9157\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3193 - accuracy: 0.9114 - val_loss: 0.3068 - val_accuracy: 0.9165\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3182 - accuracy: 0.9114 - val_loss: 0.3060 - val_accuracy: 0.9162\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3172 - accuracy: 0.9118 - val_loss: 0.3055 - val_accuracy: 0.9164\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3162 - accuracy: 0.9121 - val_loss: 0.3045 - val_accuracy: 0.9168\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3153 - accuracy: 0.9123 - val_loss: 0.3039 - val_accuracy: 0.9170\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3143 - accuracy: 0.9124 - val_loss: 0.3028 - val_accuracy: 0.9169\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3134 - accuracy: 0.9129 - val_loss: 0.3025 - val_accuracy: 0.9175\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3126 - accuracy: 0.9129 - val_loss: 0.3016 - val_accuracy: 0.9171\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3118 - accuracy: 0.9134 - val_loss: 0.3010 - val_accuracy: 0.9172\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3110 - accuracy: 0.9134 - val_loss: 0.3003 - val_accuracy: 0.9173\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3102 - accuracy: 0.9140 - val_loss: 0.2997 - val_accuracy: 0.9177\n",
      "Total compute time to train model_1a was: 48.22 seconds\n",
      "Training Accuracy: 0.9140\n",
      "Test Accuracy: 0.9177\n",
      "Training Loss: 0.3102\n",
      "Test Loss: 0.2997\n"
     ]
    }
   ],
   "source": [
    "#Single layer perceptron \n",
    "#model_1a uses epoch size of 50\n",
    "model_1a = Sequential()\n",
    "model_1a.add(Dense(units=10, activation='softmax', input_shape=(784,))) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_1a.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_1a_history = model_1a.fit(x=X_train, y=y_train, batch_size=128, epochs=50, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_1a was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_1a_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_1a_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_1a_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_1a_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.2867 - accuracy: 0.6945 - val_loss: 0.8152 - val_accuracy: 0.8339\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.7202 - accuracy: 0.8407 - val_loss: 0.6083 - val_accuracy: 0.8627\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5900 - accuracy: 0.8585 - val_loss: 0.5260 - val_accuracy: 0.8747\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.5277 - accuracy: 0.8683 - val_loss: 0.4802 - val_accuracy: 0.8805\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4898 - accuracy: 0.8742 - val_loss: 0.4501 - val_accuracy: 0.8857\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4637 - accuracy: 0.8795 - val_loss: 0.4287 - val_accuracy: 0.8887\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4444 - accuracy: 0.8835 - val_loss: 0.4128 - val_accuracy: 0.8915\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4293 - accuracy: 0.8866 - val_loss: 0.3996 - val_accuracy: 0.8952\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4172 - accuracy: 0.8884 - val_loss: 0.3895 - val_accuracy: 0.8970\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4071 - accuracy: 0.8907 - val_loss: 0.3808 - val_accuracy: 0.8971\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3986 - accuracy: 0.8922 - val_loss: 0.3733 - val_accuracy: 0.8998\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3912 - accuracy: 0.8939 - val_loss: 0.3668 - val_accuracy: 0.9013\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3848 - accuracy: 0.8953 - val_loss: 0.3614 - val_accuracy: 0.9029\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3791 - accuracy: 0.8967 - val_loss: 0.3564 - val_accuracy: 0.9042\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3740 - accuracy: 0.8976 - val_loss: 0.3521 - val_accuracy: 0.9044\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3695 - accuracy: 0.8988 - val_loss: 0.3482 - val_accuracy: 0.9055\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3653 - accuracy: 0.9001 - val_loss: 0.3445 - val_accuracy: 0.9065\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3616 - accuracy: 0.9008 - val_loss: 0.3417 - val_accuracy: 0.9062\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3581 - accuracy: 0.9014 - val_loss: 0.3383 - val_accuracy: 0.9081\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3549 - accuracy: 0.9021 - val_loss: 0.3357 - val_accuracy: 0.9088\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3520 - accuracy: 0.9028 - val_loss: 0.3331 - val_accuracy: 0.9095\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3493 - accuracy: 0.9033 - val_loss: 0.3308 - val_accuracy: 0.9095\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3467 - accuracy: 0.9039 - val_loss: 0.3287 - val_accuracy: 0.9100\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3443 - accuracy: 0.9041 - val_loss: 0.3264 - val_accuracy: 0.9107\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3421 - accuracy: 0.9045 - val_loss: 0.3246 - val_accuracy: 0.9112\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3399 - accuracy: 0.9056 - val_loss: 0.3227 - val_accuracy: 0.9116\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3380 - accuracy: 0.9056 - val_loss: 0.3211 - val_accuracy: 0.9120\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3361 - accuracy: 0.9060 - val_loss: 0.3199 - val_accuracy: 0.9122\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3343 - accuracy: 0.9067 - val_loss: 0.3181 - val_accuracy: 0.9120\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3326 - accuracy: 0.9073 - val_loss: 0.3167 - val_accuracy: 0.9122\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3310 - accuracy: 0.9075 - val_loss: 0.3155 - val_accuracy: 0.9122\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3294 - accuracy: 0.9078 - val_loss: 0.3142 - val_accuracy: 0.9129\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3279 - accuracy: 0.9079 - val_loss: 0.3132 - val_accuracy: 0.9136\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3265 - accuracy: 0.9087 - val_loss: 0.3119 - val_accuracy: 0.9130\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3252 - accuracy: 0.9090 - val_loss: 0.3109 - val_accuracy: 0.9142\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3239 - accuracy: 0.9094 - val_loss: 0.3099 - val_accuracy: 0.9139\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3227 - accuracy: 0.9097 - val_loss: 0.3088 - val_accuracy: 0.9142\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3215 - accuracy: 0.9102 - val_loss: 0.3079 - val_accuracy: 0.9143\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3203 - accuracy: 0.9104 - val_loss: 0.3071 - val_accuracy: 0.9147\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3192 - accuracy: 0.9110 - val_loss: 0.3058 - val_accuracy: 0.9151\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3182 - accuracy: 0.9113 - val_loss: 0.3050 - val_accuracy: 0.9153\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3172 - accuracy: 0.9114 - val_loss: 0.3044 - val_accuracy: 0.9161\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3162 - accuracy: 0.9117 - val_loss: 0.3035 - val_accuracy: 0.9160\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3152 - accuracy: 0.9116 - val_loss: 0.3028 - val_accuracy: 0.9163\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3143 - accuracy: 0.9126 - val_loss: 0.3023 - val_accuracy: 0.9156\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3134 - accuracy: 0.9124 - val_loss: 0.3016 - val_accuracy: 0.9160\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3125 - accuracy: 0.9129 - val_loss: 0.3006 - val_accuracy: 0.9169\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3117 - accuracy: 0.9129 - val_loss: 0.3000 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3109 - accuracy: 0.9132 - val_loss: 0.2998 - val_accuracy: 0.9161\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3102 - accuracy: 0.9134 - val_loss: 0.2990 - val_accuracy: 0.9164\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3094 - accuracy: 0.9137 - val_loss: 0.2981 - val_accuracy: 0.9165\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3086 - accuracy: 0.9138 - val_loss: 0.2977 - val_accuracy: 0.9172\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3079 - accuracy: 0.9145 - val_loss: 0.2971 - val_accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3072 - accuracy: 0.9144 - val_loss: 0.2965 - val_accuracy: 0.9172\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3065 - accuracy: 0.9149 - val_loss: 0.2960 - val_accuracy: 0.9172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3059 - accuracy: 0.9151 - val_loss: 0.2955 - val_accuracy: 0.9170\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3052 - accuracy: 0.9150 - val_loss: 0.2950 - val_accuracy: 0.9173\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3046 - accuracy: 0.9154 - val_loss: 0.2945 - val_accuracy: 0.9173\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3040 - accuracy: 0.9155 - val_loss: 0.2941 - val_accuracy: 0.9177\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3033 - accuracy: 0.9157 - val_loss: 0.2939 - val_accuracy: 0.9176\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3027 - accuracy: 0.9156 - val_loss: 0.2934 - val_accuracy: 0.9174\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3022 - accuracy: 0.9159 - val_loss: 0.2927 - val_accuracy: 0.9174\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3016 - accuracy: 0.9158 - val_loss: 0.2926 - val_accuracy: 0.9175\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3011 - accuracy: 0.9161 - val_loss: 0.2920 - val_accuracy: 0.9177\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3006 - accuracy: 0.9162 - val_loss: 0.2917 - val_accuracy: 0.9177\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3000 - accuracy: 0.9163 - val_loss: 0.2912 - val_accuracy: 0.9174\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2995 - accuracy: 0.9166 - val_loss: 0.2909 - val_accuracy: 0.9182\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2990 - accuracy: 0.9167 - val_loss: 0.2908 - val_accuracy: 0.9178\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2985 - accuracy: 0.9168 - val_loss: 0.2902 - val_accuracy: 0.9180\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2981 - accuracy: 0.9169 - val_loss: 0.2898 - val_accuracy: 0.9183\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2976 - accuracy: 0.9171 - val_loss: 0.2896 - val_accuracy: 0.9178\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2971 - accuracy: 0.9174 - val_loss: 0.2893 - val_accuracy: 0.9178\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2967 - accuracy: 0.9172 - val_loss: 0.2890 - val_accuracy: 0.9181\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2962 - accuracy: 0.9175 - val_loss: 0.2886 - val_accuracy: 0.9177\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2958 - accuracy: 0.9175 - val_loss: 0.2881 - val_accuracy: 0.9187\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2954 - accuracy: 0.9176 - val_loss: 0.2881 - val_accuracy: 0.9187\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2950 - accuracy: 0.9177 - val_loss: 0.2876 - val_accuracy: 0.9186\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2946 - accuracy: 0.9177 - val_loss: 0.2875 - val_accuracy: 0.9186\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2942 - accuracy: 0.9179 - val_loss: 0.2872 - val_accuracy: 0.9185\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2937 - accuracy: 0.9179 - val_loss: 0.2868 - val_accuracy: 0.9189\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2934 - accuracy: 0.9182 - val_loss: 0.2865 - val_accuracy: 0.9190\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2930 - accuracy: 0.9180 - val_loss: 0.2863 - val_accuracy: 0.9188\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2926 - accuracy: 0.9179 - val_loss: 0.2860 - val_accuracy: 0.9194\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2923 - accuracy: 0.9182 - val_loss: 0.2857 - val_accuracy: 0.9191\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2919 - accuracy: 0.9181 - val_loss: 0.2854 - val_accuracy: 0.9194\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2915 - accuracy: 0.9184 - val_loss: 0.2855 - val_accuracy: 0.9196\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2912 - accuracy: 0.9185 - val_loss: 0.2851 - val_accuracy: 0.9188\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2908 - accuracy: 0.9185 - val_loss: 0.2849 - val_accuracy: 0.9195\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2905 - accuracy: 0.9184 - val_loss: 0.2846 - val_accuracy: 0.9187\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2902 - accuracy: 0.9186 - val_loss: 0.2844 - val_accuracy: 0.9194\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2898 - accuracy: 0.9189 - val_loss: 0.2841 - val_accuracy: 0.9192\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2895 - accuracy: 0.9191 - val_loss: 0.2840 - val_accuracy: 0.9190\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2892 - accuracy: 0.9192 - val_loss: 0.2839 - val_accuracy: 0.9188\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2889 - accuracy: 0.9194 - val_loss: 0.2835 - val_accuracy: 0.9196\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2886 - accuracy: 0.9191 - val_loss: 0.2833 - val_accuracy: 0.9193\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2883 - accuracy: 0.9193 - val_loss: 0.2830 - val_accuracy: 0.9190\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2880 - accuracy: 0.9193 - val_loss: 0.2829 - val_accuracy: 0.9196\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2877 - accuracy: 0.9198 - val_loss: 0.2827 - val_accuracy: 0.9196\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2874 - accuracy: 0.9197 - val_loss: 0.2825 - val_accuracy: 0.9198\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2871 - accuracy: 0.9197 - val_loss: 0.2822 - val_accuracy: 0.9191\n",
      "Total compute time to train model_1b was: 88.47 seconds\n",
      "Training Accuracy: 0.9197\n",
      "Test Accuracy: 0.9191\n",
      "Training Loss: 0.2871\n",
      "Test Loss: 0.2822\n"
     ]
    }
   ],
   "source": [
    "#Single layer perceptron \n",
    "#model_1b uses epoch size of 100\n",
    "model_1b = Sequential()\n",
    "model_1b.add(Dense(units=10, activation='softmax', input_shape=(784,))) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_1b.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_1b_history = model_1b.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_1b was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_1b_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_1b_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_1b_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_1b_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.2679 - accuracy: 0.7066 - val_loss: 0.8090 - val_accuracy: 0.8340\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.7143 - accuracy: 0.8397 - val_loss: 0.6063 - val_accuracy: 0.8650\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5863 - accuracy: 0.8582 - val_loss: 0.5254 - val_accuracy: 0.8749\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5249 - accuracy: 0.8683 - val_loss: 0.4796 - val_accuracy: 0.8809\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4876 - accuracy: 0.8752 - val_loss: 0.4500 - val_accuracy: 0.8858\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4618 - accuracy: 0.8805 - val_loss: 0.4286 - val_accuracy: 0.8891\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4427 - accuracy: 0.8835 - val_loss: 0.4124 - val_accuracy: 0.8938\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4278 - accuracy: 0.8864 - val_loss: 0.3997 - val_accuracy: 0.8955\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4158 - accuracy: 0.8885 - val_loss: 0.3894 - val_accuracy: 0.8989\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4058 - accuracy: 0.8908 - val_loss: 0.3804 - val_accuracy: 0.8997\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3973 - accuracy: 0.8924 - val_loss: 0.3731 - val_accuracy: 0.9008\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3901 - accuracy: 0.8940 - val_loss: 0.3670 - val_accuracy: 0.9024\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3837 - accuracy: 0.8954 - val_loss: 0.3616 - val_accuracy: 0.9047\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3781 - accuracy: 0.8970 - val_loss: 0.3563 - val_accuracy: 0.9054\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3731 - accuracy: 0.8978 - val_loss: 0.3521 - val_accuracy: 0.9061\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3686 - accuracy: 0.8991 - val_loss: 0.3481 - val_accuracy: 0.9065\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3644 - accuracy: 0.9000 - val_loss: 0.3446 - val_accuracy: 0.9067\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3607 - accuracy: 0.9005 - val_loss: 0.3412 - val_accuracy: 0.9070\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3573 - accuracy: 0.9017 - val_loss: 0.3383 - val_accuracy: 0.9079\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3541 - accuracy: 0.9021 - val_loss: 0.3356 - val_accuracy: 0.9080\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3512 - accuracy: 0.9030 - val_loss: 0.3332 - val_accuracy: 0.9089\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3485 - accuracy: 0.9038 - val_loss: 0.3311 - val_accuracy: 0.9090\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3460 - accuracy: 0.9044 - val_loss: 0.3285 - val_accuracy: 0.9102\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3435 - accuracy: 0.9046 - val_loss: 0.3264 - val_accuracy: 0.9103\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3414 - accuracy: 0.9053 - val_loss: 0.3246 - val_accuracy: 0.9109\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3392 - accuracy: 0.9056 - val_loss: 0.3229 - val_accuracy: 0.9116\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3373 - accuracy: 0.9062 - val_loss: 0.3213 - val_accuracy: 0.9110\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3354 - accuracy: 0.9068 - val_loss: 0.3197 - val_accuracy: 0.9114\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3336 - accuracy: 0.9074 - val_loss: 0.3183 - val_accuracy: 0.9114\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3319 - accuracy: 0.9075 - val_loss: 0.3169 - val_accuracy: 0.9118\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3304 - accuracy: 0.9079 - val_loss: 0.3154 - val_accuracy: 0.9119\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3288 - accuracy: 0.9085 - val_loss: 0.3142 - val_accuracy: 0.9123\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3274 - accuracy: 0.9085 - val_loss: 0.3131 - val_accuracy: 0.9122\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3260 - accuracy: 0.9091 - val_loss: 0.3122 - val_accuracy: 0.9124\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3247 - accuracy: 0.9096 - val_loss: 0.3108 - val_accuracy: 0.9126\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3234 - accuracy: 0.9096 - val_loss: 0.3096 - val_accuracy: 0.9124\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3222 - accuracy: 0.9102 - val_loss: 0.3087 - val_accuracy: 0.9136\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3210 - accuracy: 0.9108 - val_loss: 0.3077 - val_accuracy: 0.9143\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3199 - accuracy: 0.9110 - val_loss: 0.3071 - val_accuracy: 0.9137\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3188 - accuracy: 0.9111 - val_loss: 0.3060 - val_accuracy: 0.9137\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3177 - accuracy: 0.9115 - val_loss: 0.3051 - val_accuracy: 0.9143\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3167 - accuracy: 0.9119 - val_loss: 0.3044 - val_accuracy: 0.9145\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3157 - accuracy: 0.9121 - val_loss: 0.3035 - val_accuracy: 0.9145\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3148 - accuracy: 0.9125 - val_loss: 0.3028 - val_accuracy: 0.9149\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3139 - accuracy: 0.9127 - val_loss: 0.3019 - val_accuracy: 0.9150\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3130 - accuracy: 0.9129 - val_loss: 0.3016 - val_accuracy: 0.9153\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3122 - accuracy: 0.9131 - val_loss: 0.3008 - val_accuracy: 0.9153\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3113 - accuracy: 0.9135 - val_loss: 0.3002 - val_accuracy: 0.9161\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3105 - accuracy: 0.9140 - val_loss: 0.2994 - val_accuracy: 0.9151\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3098 - accuracy: 0.9141 - val_loss: 0.2989 - val_accuracy: 0.9155\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3090 - accuracy: 0.9143 - val_loss: 0.2984 - val_accuracy: 0.9161\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3083 - accuracy: 0.9145 - val_loss: 0.2977 - val_accuracy: 0.9161\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3075 - accuracy: 0.9146 - val_loss: 0.2970 - val_accuracy: 0.9159\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3069 - accuracy: 0.9149 - val_loss: 0.2965 - val_accuracy: 0.9162\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3062 - accuracy: 0.9149 - val_loss: 0.2962 - val_accuracy: 0.9165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3055 - accuracy: 0.9154 - val_loss: 0.2955 - val_accuracy: 0.9162\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3049 - accuracy: 0.9153 - val_loss: 0.2951 - val_accuracy: 0.9167\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3042 - accuracy: 0.9158 - val_loss: 0.2947 - val_accuracy: 0.9167\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3037 - accuracy: 0.9159 - val_loss: 0.2943 - val_accuracy: 0.9168\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3030 - accuracy: 0.9160 - val_loss: 0.2939 - val_accuracy: 0.9171\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3025 - accuracy: 0.9159 - val_loss: 0.2934 - val_accuracy: 0.9167\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3019 - accuracy: 0.9162 - val_loss: 0.2930 - val_accuracy: 0.9170\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3013 - accuracy: 0.9163 - val_loss: 0.2923 - val_accuracy: 0.9173\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3008 - accuracy: 0.9162 - val_loss: 0.2922 - val_accuracy: 0.9178\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3003 - accuracy: 0.9164 - val_loss: 0.2919 - val_accuracy: 0.9176\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2998 - accuracy: 0.9166 - val_loss: 0.2913 - val_accuracy: 0.9181\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2993 - accuracy: 0.9167 - val_loss: 0.2911 - val_accuracy: 0.9178\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2988 - accuracy: 0.9170 - val_loss: 0.2908 - val_accuracy: 0.9183\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2983 - accuracy: 0.9172 - val_loss: 0.2903 - val_accuracy: 0.9183\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2978 - accuracy: 0.9174 - val_loss: 0.2902 - val_accuracy: 0.9184\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2973 - accuracy: 0.9174 - val_loss: 0.2897 - val_accuracy: 0.9187\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2969 - accuracy: 0.9175 - val_loss: 0.2895 - val_accuracy: 0.9187\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2964 - accuracy: 0.9178 - val_loss: 0.2891 - val_accuracy: 0.9184\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2960 - accuracy: 0.9177 - val_loss: 0.2890 - val_accuracy: 0.9185\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2956 - accuracy: 0.9181 - val_loss: 0.2882 - val_accuracy: 0.9189\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2952 - accuracy: 0.9182 - val_loss: 0.2880 - val_accuracy: 0.9195\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2948 - accuracy: 0.9181 - val_loss: 0.2878 - val_accuracy: 0.9189\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2944 - accuracy: 0.9182 - val_loss: 0.2875 - val_accuracy: 0.9193\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2940 - accuracy: 0.9184 - val_loss: 0.2872 - val_accuracy: 0.9191\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2936 - accuracy: 0.9184 - val_loss: 0.2870 - val_accuracy: 0.9197\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2932 - accuracy: 0.9183 - val_loss: 0.2867 - val_accuracy: 0.9195\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2928 - accuracy: 0.9184 - val_loss: 0.2866 - val_accuracy: 0.9200\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2924 - accuracy: 0.9185 - val_loss: 0.2863 - val_accuracy: 0.9196\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2921 - accuracy: 0.9186 - val_loss: 0.2862 - val_accuracy: 0.9197\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2917 - accuracy: 0.9186 - val_loss: 0.2856 - val_accuracy: 0.9198\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2914 - accuracy: 0.9189 - val_loss: 0.2854 - val_accuracy: 0.9198\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2910 - accuracy: 0.9186 - val_loss: 0.2851 - val_accuracy: 0.9198\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2907 - accuracy: 0.9188 - val_loss: 0.2849 - val_accuracy: 0.9201\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2904 - accuracy: 0.9187 - val_loss: 0.2849 - val_accuracy: 0.9205\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2900 - accuracy: 0.9191 - val_loss: 0.2846 - val_accuracy: 0.9204\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2897 - accuracy: 0.9191 - val_loss: 0.2843 - val_accuracy: 0.9199\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2894 - accuracy: 0.9193 - val_loss: 0.2842 - val_accuracy: 0.9201\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2891 - accuracy: 0.9192 - val_loss: 0.2840 - val_accuracy: 0.9202\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2887 - accuracy: 0.9193 - val_loss: 0.2839 - val_accuracy: 0.9199\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2885 - accuracy: 0.9195 - val_loss: 0.2835 - val_accuracy: 0.9203\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2882 - accuracy: 0.9195 - val_loss: 0.2834 - val_accuracy: 0.9197\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2879 - accuracy: 0.9195 - val_loss: 0.2832 - val_accuracy: 0.9201\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2876 - accuracy: 0.9196 - val_loss: 0.2829 - val_accuracy: 0.9209\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2873 - accuracy: 0.9196 - val_loss: 0.2827 - val_accuracy: 0.9205\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2870 - accuracy: 0.9197 - val_loss: 0.2827 - val_accuracy: 0.9214\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2867 - accuracy: 0.9198 - val_loss: 0.2823 - val_accuracy: 0.9208\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2864 - accuracy: 0.9201 - val_loss: 0.2824 - val_accuracy: 0.9208\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2862 - accuracy: 0.9201 - val_loss: 0.2822 - val_accuracy: 0.9215\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2859 - accuracy: 0.9202 - val_loss: 0.2820 - val_accuracy: 0.9211\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2857 - accuracy: 0.9204 - val_loss: 0.2816 - val_accuracy: 0.9212\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2854 - accuracy: 0.9204 - val_loss: 0.2814 - val_accuracy: 0.9207\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2851 - accuracy: 0.9202 - val_loss: 0.2812 - val_accuracy: 0.9213\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2849 - accuracy: 0.9201 - val_loss: 0.2813 - val_accuracy: 0.9216\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2846 - accuracy: 0.9206 - val_loss: 0.2810 - val_accuracy: 0.9219\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2844 - accuracy: 0.9204 - val_loss: 0.2809 - val_accuracy: 0.9216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2841 - accuracy: 0.9208 - val_loss: 0.2809 - val_accuracy: 0.9211\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2839 - accuracy: 0.9207 - val_loss: 0.2806 - val_accuracy: 0.9217\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2836 - accuracy: 0.9208 - val_loss: 0.2803 - val_accuracy: 0.9218\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2834 - accuracy: 0.9210 - val_loss: 0.2803 - val_accuracy: 0.9216\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2832 - accuracy: 0.9210 - val_loss: 0.2804 - val_accuracy: 0.9213\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2830 - accuracy: 0.9212 - val_loss: 0.2801 - val_accuracy: 0.9215\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2828 - accuracy: 0.9212 - val_loss: 0.2800 - val_accuracy: 0.9213\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2825 - accuracy: 0.9212 - val_loss: 0.2801 - val_accuracy: 0.9214\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2823 - accuracy: 0.9212 - val_loss: 0.2797 - val_accuracy: 0.9218\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2821 - accuracy: 0.9215 - val_loss: 0.2795 - val_accuracy: 0.9216\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2819 - accuracy: 0.9216 - val_loss: 0.2793 - val_accuracy: 0.9219\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2816 - accuracy: 0.9215 - val_loss: 0.2794 - val_accuracy: 0.9218\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2814 - accuracy: 0.9216 - val_loss: 0.2792 - val_accuracy: 0.9220\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2813 - accuracy: 0.9218 - val_loss: 0.2789 - val_accuracy: 0.9219\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2810 - accuracy: 0.9217 - val_loss: 0.2788 - val_accuracy: 0.9216\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2808 - accuracy: 0.9218 - val_loss: 0.2788 - val_accuracy: 0.9223\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2806 - accuracy: 0.9220 - val_loss: 0.2788 - val_accuracy: 0.9217\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2804 - accuracy: 0.9220 - val_loss: 0.2785 - val_accuracy: 0.9220\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2802 - accuracy: 0.9220 - val_loss: 0.2784 - val_accuracy: 0.9225\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2800 - accuracy: 0.9221 - val_loss: 0.2784 - val_accuracy: 0.9208\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2799 - accuracy: 0.9222 - val_loss: 0.2782 - val_accuracy: 0.9215\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2797 - accuracy: 0.9221 - val_loss: 0.2781 - val_accuracy: 0.9212\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2795 - accuracy: 0.9220 - val_loss: 0.2779 - val_accuracy: 0.9211\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2793 - accuracy: 0.9222 - val_loss: 0.2778 - val_accuracy: 0.9220\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2791 - accuracy: 0.9224 - val_loss: 0.2776 - val_accuracy: 0.9224\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2789 - accuracy: 0.9224 - val_loss: 0.2776 - val_accuracy: 0.9216\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2787 - accuracy: 0.9225 - val_loss: 0.2773 - val_accuracy: 0.9218\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2785 - accuracy: 0.9226 - val_loss: 0.2775 - val_accuracy: 0.9223\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2783 - accuracy: 0.9224 - val_loss: 0.2776 - val_accuracy: 0.9218\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2782 - accuracy: 0.9224 - val_loss: 0.2774 - val_accuracy: 0.9225\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2780 - accuracy: 0.9225 - val_loss: 0.2772 - val_accuracy: 0.9229\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2779 - accuracy: 0.9226 - val_loss: 0.2769 - val_accuracy: 0.9223\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2777 - accuracy: 0.9228 - val_loss: 0.2770 - val_accuracy: 0.9225\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2775 - accuracy: 0.9230 - val_loss: 0.2767 - val_accuracy: 0.9230\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2774 - accuracy: 0.9229 - val_loss: 0.2767 - val_accuracy: 0.9221\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2772 - accuracy: 0.9230 - val_loss: 0.2766 - val_accuracy: 0.9218\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2770 - accuracy: 0.9230 - val_loss: 0.2764 - val_accuracy: 0.9224\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2768 - accuracy: 0.9230 - val_loss: 0.2765 - val_accuracy: 0.9231\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2767 - accuracy: 0.9232 - val_loss: 0.2762 - val_accuracy: 0.9228\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2766 - accuracy: 0.9231 - val_loss: 0.2762 - val_accuracy: 0.9225\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2764 - accuracy: 0.9232 - val_loss: 0.2762 - val_accuracy: 0.9233\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2762 - accuracy: 0.9234 - val_loss: 0.2761 - val_accuracy: 0.9228\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2761 - accuracy: 0.9234 - val_loss: 0.2761 - val_accuracy: 0.9225\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2759 - accuracy: 0.9236 - val_loss: 0.2759 - val_accuracy: 0.9233\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2758 - accuracy: 0.9236 - val_loss: 0.2757 - val_accuracy: 0.9233\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2756 - accuracy: 0.9235 - val_loss: 0.2757 - val_accuracy: 0.9233\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2755 - accuracy: 0.9237 - val_loss: 0.2757 - val_accuracy: 0.9233\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2753 - accuracy: 0.9235 - val_loss: 0.2756 - val_accuracy: 0.9230\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2751 - accuracy: 0.9238 - val_loss: 0.2754 - val_accuracy: 0.9223\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2750 - accuracy: 0.9237 - val_loss: 0.2754 - val_accuracy: 0.9230\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2749 - accuracy: 0.9237 - val_loss: 0.2752 - val_accuracy: 0.9233\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2747 - accuracy: 0.9238 - val_loss: 0.2754 - val_accuracy: 0.9226\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2746 - accuracy: 0.9238 - val_loss: 0.2754 - val_accuracy: 0.9222\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2745 - accuracy: 0.9238 - val_loss: 0.2751 - val_accuracy: 0.9232\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2743 - accuracy: 0.9238 - val_loss: 0.2748 - val_accuracy: 0.9231\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2742 - accuracy: 0.9236 - val_loss: 0.2749 - val_accuracy: 0.9227\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2741 - accuracy: 0.9240 - val_loss: 0.2750 - val_accuracy: 0.9229\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2739 - accuracy: 0.9240 - val_loss: 0.2748 - val_accuracy: 0.9228\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2738 - accuracy: 0.9240 - val_loss: 0.2748 - val_accuracy: 0.9225\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2736 - accuracy: 0.9241 - val_loss: 0.2750 - val_accuracy: 0.9222\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2735 - accuracy: 0.9240 - val_loss: 0.2746 - val_accuracy: 0.9232\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2734 - accuracy: 0.9241 - val_loss: 0.2745 - val_accuracy: 0.9229\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2732 - accuracy: 0.9243 - val_loss: 0.2743 - val_accuracy: 0.9233\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2731 - accuracy: 0.9242 - val_loss: 0.2743 - val_accuracy: 0.9228\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2730 - accuracy: 0.9245 - val_loss: 0.2742 - val_accuracy: 0.9232\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2729 - accuracy: 0.9244 - val_loss: 0.2743 - val_accuracy: 0.9228\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2727 - accuracy: 0.9245 - val_loss: 0.2740 - val_accuracy: 0.9222\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2726 - accuracy: 0.9244 - val_loss: 0.2741 - val_accuracy: 0.9221\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2725 - accuracy: 0.9243 - val_loss: 0.2739 - val_accuracy: 0.9226\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2723 - accuracy: 0.9245 - val_loss: 0.2740 - val_accuracy: 0.9229\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2722 - accuracy: 0.9245 - val_loss: 0.2736 - val_accuracy: 0.9231\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2721 - accuracy: 0.9245 - val_loss: 0.2737 - val_accuracy: 0.9228\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2720 - accuracy: 0.9246 - val_loss: 0.2737 - val_accuracy: 0.9224\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2719 - accuracy: 0.9246 - val_loss: 0.2737 - val_accuracy: 0.9229\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2718 - accuracy: 0.9250 - val_loss: 0.2738 - val_accuracy: 0.9229\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2716 - accuracy: 0.9247 - val_loss: 0.2736 - val_accuracy: 0.9231\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2715 - accuracy: 0.9248 - val_loss: 0.2737 - val_accuracy: 0.9228\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2714 - accuracy: 0.9248 - val_loss: 0.2735 - val_accuracy: 0.9232\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2713 - accuracy: 0.9247 - val_loss: 0.2735 - val_accuracy: 0.9230\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2712 - accuracy: 0.9248 - val_loss: 0.2733 - val_accuracy: 0.9232\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2711 - accuracy: 0.9247 - val_loss: 0.2735 - val_accuracy: 0.9226\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2709 - accuracy: 0.9250 - val_loss: 0.2733 - val_accuracy: 0.9225\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2708 - accuracy: 0.9248 - val_loss: 0.2732 - val_accuracy: 0.9228\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2707 - accuracy: 0.9251 - val_loss: 0.2731 - val_accuracy: 0.9223\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2706 - accuracy: 0.9251 - val_loss: 0.2731 - val_accuracy: 0.9226\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2705 - accuracy: 0.9251 - val_loss: 0.2732 - val_accuracy: 0.9224\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2704 - accuracy: 0.9250 - val_loss: 0.2728 - val_accuracy: 0.9227\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2703 - accuracy: 0.9248 - val_loss: 0.2728 - val_accuracy: 0.9226\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2701 - accuracy: 0.9249 - val_loss: 0.2727 - val_accuracy: 0.9227\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2701 - accuracy: 0.9252 - val_loss: 0.2729 - val_accuracy: 0.9225\n",
      "Total compute time to train model_1c was: 174.17 seconds\n",
      "Training Accuracy: 0.9252\n",
      "Test Accuracy: 0.9225\n",
      "Training Loss: 0.2701\n",
      "Test Loss: 0.2729\n"
     ]
    }
   ],
   "source": [
    "#Single layer perceptron \n",
    "#model_1c uses epoch size of 200\n",
    "model_1c = Sequential()\n",
    "model_1c.add(Dense(units=10, activation='softmax', input_shape=(784,))) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_1c.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_1c_history = model_1c.fit(x=X_train, y=y_train, batch_size=128, epochs=200, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_1c was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_1c_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_1c_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_1c_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_1c_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Plotting accuracy of SLP models i.e model_1a, model_1b and model_1c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.091, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting model_1a accuracy\n",
    "model_1a_history_df = pd.DataFrame(model_1a_history.history) #converting history dictionary to pandas dataframe\n",
    "model_1a_history_df = model_1a_history_df.apply(lambda x : round(x,4), axis=1) # rounding values to 3 decimal places\n",
    "model_1a_history_df.columns = ['Test Loss', 'Test Accuracy', 'Training Loss', 'Training Accuracy'] # renaming columns\n",
    "\n",
    "\n",
    "model_1b_history_df = pd.DataFrame(model_1b_history.history) #converting history dictionary to pandas dataframe\n",
    "model_1b_history_df = model_1b_history_df.apply(lambda x : round(x,4), axis=1) # rounding values to 3 decimal places\n",
    "model_1b_history_df.columns = ['Test Loss', 'Test Accuracy', 'Training Loss', 'Training Accuracy'] # renaming columns\n",
    "\n",
    "\n",
    "model_1c_history_df = pd.DataFrame(model_1c_history.history) #converting history dictionary to pandas dataframe\n",
    "model_1c_history_df = model_1c_history_df.apply(lambda x : round(x,4), axis=1) # rounding values to 3 decimal places\n",
    "model_1c_history_df.columns = ['Test Loss', 'Test Accuracy', 'Training Loss', 'Training Accuracy'] # renaming columns\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
    "model_1a_history_df[['Training Accuracy','Test Accuracy']].plot(ax=ax[0], title='model_1a')\n",
    "model_1b_history_df[['Training Accuracy','Test Accuracy']].plot(ax=ax[1], title='model_1b')\n",
    "model_1c_history_df[['Training Accuracy','Test Accuracy']].plot(ax=ax[2], title='mode1_1c')\n",
    "fig.text(0.5, 0.04, 'Number of Epochs')\n",
    "fig.text(0.091, 0.5, 'Accuracy', va='center', rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Invesigating Effect of Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.2689 - accuracy: 0.7052 - val_loss: 0.8065 - val_accuracy: 0.8308\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7149 - accuracy: 0.8398 - val_loss: 0.6061 - val_accuracy: 0.8636\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5874 - accuracy: 0.8587 - val_loss: 0.5255 - val_accuracy: 0.8746\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5259 - accuracy: 0.8678 - val_loss: 0.4801 - val_accuracy: 0.8816\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4884 - accuracy: 0.8743 - val_loss: 0.4506 - val_accuracy: 0.8866\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4625 - accuracy: 0.8790 - val_loss: 0.4291 - val_accuracy: 0.8903\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4434 - accuracy: 0.8826 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4283 - accuracy: 0.8851 - val_loss: 0.4000 - val_accuracy: 0.8958\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4163 - accuracy: 0.8881 - val_loss: 0.3896 - val_accuracy: 0.8976\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4062 - accuracy: 0.8900 - val_loss: 0.3806 - val_accuracy: 0.8993\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3977 - accuracy: 0.8918 - val_loss: 0.3734 - val_accuracy: 0.9011\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3904 - accuracy: 0.8934 - val_loss: 0.3670 - val_accuracy: 0.9024\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3840 - accuracy: 0.8950 - val_loss: 0.3616 - val_accuracy: 0.9027\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3783 - accuracy: 0.8962 - val_loss: 0.3567 - val_accuracy: 0.9044\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3732 - accuracy: 0.8975 - val_loss: 0.3524 - val_accuracy: 0.9051\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3687 - accuracy: 0.8986 - val_loss: 0.3482 - val_accuracy: 0.9062\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3646 - accuracy: 0.8997 - val_loss: 0.3445 - val_accuracy: 0.9067\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3608 - accuracy: 0.9007 - val_loss: 0.3414 - val_accuracy: 0.9078\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3574 - accuracy: 0.9014 - val_loss: 0.3385 - val_accuracy: 0.9083\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3542 - accuracy: 0.9022 - val_loss: 0.3357 - val_accuracy: 0.9089\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3512 - accuracy: 0.9031 - val_loss: 0.3332 - val_accuracy: 0.9095\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3485 - accuracy: 0.9035 - val_loss: 0.3309 - val_accuracy: 0.9091\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3459 - accuracy: 0.9043 - val_loss: 0.3287 - val_accuracy: 0.9097\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3436 - accuracy: 0.9050 - val_loss: 0.3268 - val_accuracy: 0.9104\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3413 - accuracy: 0.9055 - val_loss: 0.3251 - val_accuracy: 0.9108\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3392 - accuracy: 0.9060 - val_loss: 0.3233 - val_accuracy: 0.9113\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3372 - accuracy: 0.9069 - val_loss: 0.3214 - val_accuracy: 0.9116\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3353 - accuracy: 0.9070 - val_loss: 0.3197 - val_accuracy: 0.9119\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3336 - accuracy: 0.9074 - val_loss: 0.3182 - val_accuracy: 0.9121\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3319 - accuracy: 0.9081 - val_loss: 0.3170 - val_accuracy: 0.9124\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3302 - accuracy: 0.9081 - val_loss: 0.3156 - val_accuracy: 0.9126\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3287 - accuracy: 0.9088 - val_loss: 0.3142 - val_accuracy: 0.9130\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3272 - accuracy: 0.9089 - val_loss: 0.3128 - val_accuracy: 0.9130\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3259 - accuracy: 0.9096 - val_loss: 0.3120 - val_accuracy: 0.9135\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3245 - accuracy: 0.9096 - val_loss: 0.3110 - val_accuracy: 0.9135\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3232 - accuracy: 0.9101 - val_loss: 0.3099 - val_accuracy: 0.9139\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3220 - accuracy: 0.9105 - val_loss: 0.3090 - val_accuracy: 0.9142\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3208 - accuracy: 0.9107 - val_loss: 0.3078 - val_accuracy: 0.9143\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3197 - accuracy: 0.9109 - val_loss: 0.3070 - val_accuracy: 0.9149\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3186 - accuracy: 0.9113 - val_loss: 0.3061 - val_accuracy: 0.9143\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3176 - accuracy: 0.9116 - val_loss: 0.3053 - val_accuracy: 0.9152\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3165 - accuracy: 0.9119 - val_loss: 0.3044 - val_accuracy: 0.9154\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3156 - accuracy: 0.9123 - val_loss: 0.3035 - val_accuracy: 0.9155\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3146 - accuracy: 0.9128 - val_loss: 0.3028 - val_accuracy: 0.9161\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3137 - accuracy: 0.9128 - val_loss: 0.3021 - val_accuracy: 0.9164\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3128 - accuracy: 0.9132 - val_loss: 0.3013 - val_accuracy: 0.9164\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3120 - accuracy: 0.9135 - val_loss: 0.3008 - val_accuracy: 0.9160\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3111 - accuracy: 0.9135 - val_loss: 0.3003 - val_accuracy: 0.9165\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3103 - accuracy: 0.9140 - val_loss: 0.2997 - val_accuracy: 0.9171\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3095 - accuracy: 0.9142 - val_loss: 0.2991 - val_accuracy: 0.9166\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3087 - accuracy: 0.9144 - val_loss: 0.2984 - val_accuracy: 0.9168\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3081 - accuracy: 0.9143 - val_loss: 0.2980 - val_accuracy: 0.9172\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3073 - accuracy: 0.9147 - val_loss: 0.2975 - val_accuracy: 0.9176\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3067 - accuracy: 0.9146 - val_loss: 0.2968 - val_accuracy: 0.9170\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3060 - accuracy: 0.9152 - val_loss: 0.2962 - val_accuracy: 0.9176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3053 - accuracy: 0.9152 - val_loss: 0.2958 - val_accuracy: 0.9177\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3047 - accuracy: 0.9155 - val_loss: 0.2954 - val_accuracy: 0.9184\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3040 - accuracy: 0.9158 - val_loss: 0.2949 - val_accuracy: 0.9181\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3034 - accuracy: 0.9160 - val_loss: 0.2945 - val_accuracy: 0.9188\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3028 - accuracy: 0.9158 - val_loss: 0.2937 - val_accuracy: 0.9186\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3022 - accuracy: 0.9163 - val_loss: 0.2934 - val_accuracy: 0.9184\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3016 - accuracy: 0.9162 - val_loss: 0.2931 - val_accuracy: 0.9184\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3011 - accuracy: 0.9163 - val_loss: 0.2928 - val_accuracy: 0.9193\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3006 - accuracy: 0.9167 - val_loss: 0.2921 - val_accuracy: 0.9187\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3000 - accuracy: 0.9169 - val_loss: 0.2921 - val_accuracy: 0.9186\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2996 - accuracy: 0.9171 - val_loss: 0.2914 - val_accuracy: 0.9191\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2990 - accuracy: 0.9169 - val_loss: 0.2913 - val_accuracy: 0.9192\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2985 - accuracy: 0.9172 - val_loss: 0.2907 - val_accuracy: 0.9187\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2980 - accuracy: 0.9173 - val_loss: 0.2905 - val_accuracy: 0.9190\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2976 - accuracy: 0.9172 - val_loss: 0.2902 - val_accuracy: 0.9193\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2971 - accuracy: 0.9176 - val_loss: 0.2897 - val_accuracy: 0.9192\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2967 - accuracy: 0.9175 - val_loss: 0.2894 - val_accuracy: 0.9199\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2962 - accuracy: 0.9179 - val_loss: 0.2891 - val_accuracy: 0.9200\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2958 - accuracy: 0.9178 - val_loss: 0.2890 - val_accuracy: 0.9192\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2954 - accuracy: 0.9181 - val_loss: 0.2887 - val_accuracy: 0.9195\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2949 - accuracy: 0.9180 - val_loss: 0.2882 - val_accuracy: 0.9198\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2945 - accuracy: 0.9183 - val_loss: 0.2877 - val_accuracy: 0.9201\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2941 - accuracy: 0.9185 - val_loss: 0.2877 - val_accuracy: 0.9198\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2937 - accuracy: 0.9187 - val_loss: 0.2872 - val_accuracy: 0.9200\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2933 - accuracy: 0.9186 - val_loss: 0.2871 - val_accuracy: 0.9201\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2930 - accuracy: 0.9183 - val_loss: 0.2867 - val_accuracy: 0.9200\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2925 - accuracy: 0.9188 - val_loss: 0.2864 - val_accuracy: 0.9206\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2922 - accuracy: 0.9188 - val_loss: 0.2860 - val_accuracy: 0.9201\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2919 - accuracy: 0.9190 - val_loss: 0.2860 - val_accuracy: 0.9207\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2915 - accuracy: 0.9190 - val_loss: 0.2858 - val_accuracy: 0.9203\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2911 - accuracy: 0.9193 - val_loss: 0.2854 - val_accuracy: 0.9206\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2908 - accuracy: 0.9195 - val_loss: 0.2853 - val_accuracy: 0.9202\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2905 - accuracy: 0.9197 - val_loss: 0.2852 - val_accuracy: 0.9204\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2901 - accuracy: 0.9197 - val_loss: 0.2846 - val_accuracy: 0.9207\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2898 - accuracy: 0.9194 - val_loss: 0.2845 - val_accuracy: 0.9207\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2895 - accuracy: 0.9197 - val_loss: 0.2845 - val_accuracy: 0.9206\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2891 - accuracy: 0.9199 - val_loss: 0.2842 - val_accuracy: 0.9209\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2888 - accuracy: 0.9197 - val_loss: 0.2839 - val_accuracy: 0.9205\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2885 - accuracy: 0.9200 - val_loss: 0.2839 - val_accuracy: 0.9209\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2882 - accuracy: 0.9202 - val_loss: 0.2835 - val_accuracy: 0.9209\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2879 - accuracy: 0.9202 - val_loss: 0.2832 - val_accuracy: 0.9210\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2876 - accuracy: 0.9201 - val_loss: 0.2832 - val_accuracy: 0.9208\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2873 - accuracy: 0.9204 - val_loss: 0.2832 - val_accuracy: 0.9206\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2871 - accuracy: 0.9205 - val_loss: 0.2826 - val_accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2867 - accuracy: 0.9206 - val_loss: 0.2828 - val_accuracy: 0.9214\n",
      "Total compute time to train model_2a was: 96.12 seconds\n",
      "Training Accuracy: 0.9206\n",
      "Test Accuracy: 0.9214\n",
      "Training Loss: 0.2867\n",
      "Test Loss: 0.2828\n"
     ]
    }
   ],
   "source": [
    "#Single layer perceptron \n",
    "#model_2a uses batch size of 128\n",
    "model_2a = Sequential()\n",
    "model_2a.add(Dense(units=10, activation='softmax', input_shape=(784,))) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_2a.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_2a_history = model_2a.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_2a was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_2a_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_2a_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_2a_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_2a_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.5846 - accuracy: 0.5999 - val_loss: 1.1080 - val_accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.9563 - accuracy: 0.8036 - val_loss: 0.8064 - val_accuracy: 0.8344\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.7606 - accuracy: 0.8333 - val_loss: 0.6783 - val_accuracy: 0.8547\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.6643 - accuracy: 0.8469 - val_loss: 0.6062 - val_accuracy: 0.8630\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6057 - accuracy: 0.8558 - val_loss: 0.5594 - val_accuracy: 0.8701\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5658 - accuracy: 0.8621 - val_loss: 0.5258 - val_accuracy: 0.8740\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.5363 - accuracy: 0.8662 - val_loss: 0.5006 - val_accuracy: 0.8770\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.5136 - accuracy: 0.8702 - val_loss: 0.4807 - val_accuracy: 0.8797\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.4953 - accuracy: 0.8731 - val_loss: 0.4647 - val_accuracy: 0.8827\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.4803 - accuracy: 0.8755 - val_loss: 0.4512 - val_accuracy: 0.8842\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4676 - accuracy: 0.8782 - val_loss: 0.4397 - val_accuracy: 0.8867\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4568 - accuracy: 0.8802 - val_loss: 0.4300 - val_accuracy: 0.8876\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.4474 - accuracy: 0.8817 - val_loss: 0.4213 - val_accuracy: 0.8895\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4391 - accuracy: 0.8836 - val_loss: 0.4138 - val_accuracy: 0.8907\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4317 - accuracy: 0.8851 - val_loss: 0.4072 - val_accuracy: 0.8918\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4251 - accuracy: 0.8863 - val_loss: 0.4011 - val_accuracy: 0.8939\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4191 - accuracy: 0.8875 - val_loss: 0.3955 - val_accuracy: 0.8953\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.4137 - accuracy: 0.8883 - val_loss: 0.3907 - val_accuracy: 0.8959\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4087 - accuracy: 0.8896 - val_loss: 0.3863 - val_accuracy: 0.8968\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4041 - accuracy: 0.8906 - val_loss: 0.3820 - val_accuracy: 0.8977\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3999 - accuracy: 0.8916 - val_loss: 0.3780 - val_accuracy: 0.8991\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3960 - accuracy: 0.8922 - val_loss: 0.3747 - val_accuracy: 0.8984\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3923 - accuracy: 0.8930 - val_loss: 0.3711 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3889 - accuracy: 0.8937 - val_loss: 0.3680 - val_accuracy: 0.9006\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3858 - accuracy: 0.8946 - val_loss: 0.3653 - val_accuracy: 0.9024\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3828 - accuracy: 0.8952 - val_loss: 0.3624 - val_accuracy: 0.9019\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3800 - accuracy: 0.8960 - val_loss: 0.3600 - val_accuracy: 0.9024\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3773 - accuracy: 0.8964 - val_loss: 0.3576 - val_accuracy: 0.9034\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3748 - accuracy: 0.8968 - val_loss: 0.3552 - val_accuracy: 0.9037\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.3724 - accuracy: 0.8975 - val_loss: 0.3531 - val_accuracy: 0.9044\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3701 - accuracy: 0.8979 - val_loss: 0.3511 - val_accuracy: 0.9043\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3679 - accuracy: 0.8985 - val_loss: 0.3491 - val_accuracy: 0.9042\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3659 - accuracy: 0.8987 - val_loss: 0.3471 - val_accuracy: 0.9054\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3639 - accuracy: 0.8993 - val_loss: 0.3455 - val_accuracy: 0.9061\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3621 - accuracy: 0.8998 - val_loss: 0.3440 - val_accuracy: 0.9064\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3603 - accuracy: 0.9002 - val_loss: 0.3422 - val_accuracy: 0.9074\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3586 - accuracy: 0.9004 - val_loss: 0.3408 - val_accuracy: 0.9080\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3569 - accuracy: 0.9009 - val_loss: 0.3393 - val_accuracy: 0.9084\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3553 - accuracy: 0.9012 - val_loss: 0.3379 - val_accuracy: 0.9082\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3538 - accuracy: 0.9018 - val_loss: 0.3364 - val_accuracy: 0.9087\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3523 - accuracy: 0.9023 - val_loss: 0.3351 - val_accuracy: 0.9091\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3509 - accuracy: 0.9022 - val_loss: 0.3338 - val_accuracy: 0.9086\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3495 - accuracy: 0.9026 - val_loss: 0.3327 - val_accuracy: 0.9090\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3482 - accuracy: 0.9029 - val_loss: 0.3316 - val_accuracy: 0.9097\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3469 - accuracy: 0.9033 - val_loss: 0.3304 - val_accuracy: 0.9101\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3457 - accuracy: 0.9035 - val_loss: 0.3294 - val_accuracy: 0.9104\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3445 - accuracy: 0.9041 - val_loss: 0.3284 - val_accuracy: 0.9107\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3434 - accuracy: 0.9044 - val_loss: 0.3274 - val_accuracy: 0.9107\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3422 - accuracy: 0.9046 - val_loss: 0.3264 - val_accuracy: 0.9111\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3412 - accuracy: 0.9047 - val_loss: 0.3255 - val_accuracy: 0.9116\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3401 - accuracy: 0.9050 - val_loss: 0.3246 - val_accuracy: 0.9115\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3391 - accuracy: 0.9053 - val_loss: 0.3235 - val_accuracy: 0.9119\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3381 - accuracy: 0.9056 - val_loss: 0.3227 - val_accuracy: 0.9118\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3371 - accuracy: 0.9057 - val_loss: 0.3219 - val_accuracy: 0.9116\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3362 - accuracy: 0.9058 - val_loss: 0.3210 - val_accuracy: 0.9120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.3353 - accuracy: 0.9063 - val_loss: 0.3203 - val_accuracy: 0.9123\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3344 - accuracy: 0.9064 - val_loss: 0.3195 - val_accuracy: 0.9127\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3335 - accuracy: 0.9068 - val_loss: 0.3187 - val_accuracy: 0.9127\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3327 - accuracy: 0.9069 - val_loss: 0.3180 - val_accuracy: 0.9129\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3318 - accuracy: 0.9073 - val_loss: 0.3172 - val_accuracy: 0.9132\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3310 - accuracy: 0.9074 - val_loss: 0.3167 - val_accuracy: 0.9137\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3302 - accuracy: 0.9076 - val_loss: 0.3158 - val_accuracy: 0.9137\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3295 - accuracy: 0.9079 - val_loss: 0.3152 - val_accuracy: 0.9137\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3287 - accuracy: 0.9081 - val_loss: 0.3147 - val_accuracy: 0.9143\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3280 - accuracy: 0.9086 - val_loss: 0.3141 - val_accuracy: 0.9142\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3273 - accuracy: 0.9086 - val_loss: 0.3135 - val_accuracy: 0.9142\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3266 - accuracy: 0.9089 - val_loss: 0.3129 - val_accuracy: 0.9143\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3259 - accuracy: 0.9091 - val_loss: 0.3124 - val_accuracy: 0.9141\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3252 - accuracy: 0.9094 - val_loss: 0.3119 - val_accuracy: 0.9141\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3246 - accuracy: 0.9094 - val_loss: 0.3112 - val_accuracy: 0.9150\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3239 - accuracy: 0.9098 - val_loss: 0.3107 - val_accuracy: 0.9152\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3233 - accuracy: 0.9099 - val_loss: 0.3101 - val_accuracy: 0.9150\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.3227 - accuracy: 0.9102 - val_loss: 0.3097 - val_accuracy: 0.9158\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3221 - accuracy: 0.9104 - val_loss: 0.3091 - val_accuracy: 0.9161\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.3215 - accuracy: 0.9104 - val_loss: 0.3087 - val_accuracy: 0.9158\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.3209 - accuracy: 0.9106 - val_loss: 0.3081 - val_accuracy: 0.9163\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3203 - accuracy: 0.9109 - val_loss: 0.3076 - val_accuracy: 0.9164\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3198 - accuracy: 0.9108 - val_loss: 0.3073 - val_accuracy: 0.9162\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3192 - accuracy: 0.9111 - val_loss: 0.3069 - val_accuracy: 0.9164\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3187 - accuracy: 0.9115 - val_loss: 0.3064 - val_accuracy: 0.9165\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.3182 - accuracy: 0.9116 - val_loss: 0.3058 - val_accuracy: 0.9166\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3176 - accuracy: 0.9117 - val_loss: 0.3055 - val_accuracy: 0.9169\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3172 - accuracy: 0.9121 - val_loss: 0.3051 - val_accuracy: 0.9170\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3166 - accuracy: 0.9119 - val_loss: 0.3047 - val_accuracy: 0.9169\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3162 - accuracy: 0.9122 - val_loss: 0.3043 - val_accuracy: 0.9167\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3157 - accuracy: 0.9123 - val_loss: 0.3041 - val_accuracy: 0.9165\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.3152 - accuracy: 0.9123 - val_loss: 0.3035 - val_accuracy: 0.9171\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3147 - accuracy: 0.9124 - val_loss: 0.3031 - val_accuracy: 0.9176\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3143 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.9172\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3138 - accuracy: 0.9125 - val_loss: 0.3024 - val_accuracy: 0.9170\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3134 - accuracy: 0.9128 - val_loss: 0.3020 - val_accuracy: 0.9175\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3129 - accuracy: 0.9129 - val_loss: 0.3018 - val_accuracy: 0.9180\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3125 - accuracy: 0.9131 - val_loss: 0.3013 - val_accuracy: 0.9181\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3121 - accuracy: 0.9132 - val_loss: 0.3010 - val_accuracy: 0.9176\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3117 - accuracy: 0.9134 - val_loss: 0.3008 - val_accuracy: 0.9177\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3113 - accuracy: 0.9134 - val_loss: 0.3003 - val_accuracy: 0.9181\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3109 - accuracy: 0.9135 - val_loss: 0.3000 - val_accuracy: 0.9182\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3105 - accuracy: 0.9138 - val_loss: 0.2998 - val_accuracy: 0.9180\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3101 - accuracy: 0.9139 - val_loss: 0.2995 - val_accuracy: 0.9179\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3097 - accuracy: 0.9140 - val_loss: 0.2992 - val_accuracy: 0.9180\n",
      "Total compute time to train model_2b was: 59.71 seconds\n",
      "Training Accuracy: 0.9140\n",
      "Test Accuracy: 0.9180\n",
      "Training Loss: 0.3097\n",
      "Test Loss: 0.2992\n"
     ]
    }
   ],
   "source": [
    "#Single layer perceptron \n",
    "#model_2b uses batch size of 256\n",
    "model_2b = Sequential()\n",
    "model_2b.add(Dense(units=10, activation='softmax', input_shape=(784,))) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_2b.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_2b_history = model_2b.fit(x=X_train, y=y_train, batch_size=256, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_2b was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_2b_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_2b_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_2b_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_2b_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.9047 - accuracy: 0.4309 - val_loss: 1.5046 - val_accuracy: 0.6877\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.3113 - accuracy: 0.7369 - val_loss: 1.1200 - val_accuracy: 0.7875\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.0386 - accuracy: 0.7941 - val_loss: 0.9249 - val_accuracy: 0.8210\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.8892 - accuracy: 0.8164 - val_loss: 0.8095 - val_accuracy: 0.8354\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.7955 - accuracy: 0.8293 - val_loss: 0.7331 - val_accuracy: 0.8446\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.7309 - accuracy: 0.8381 - val_loss: 0.6786 - val_accuracy: 0.8527\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.6834 - accuracy: 0.8451 - val_loss: 0.6375 - val_accuracy: 0.8599\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.6467 - accuracy: 0.8513 - val_loss: 0.6052 - val_accuracy: 0.8643\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.6175 - accuracy: 0.8554 - val_loss: 0.5791 - val_accuracy: 0.8669\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5935 - accuracy: 0.8591 - val_loss: 0.5574 - val_accuracy: 0.8697\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5734 - accuracy: 0.8620 - val_loss: 0.5393 - val_accuracy: 0.8732\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5563 - accuracy: 0.8646 - val_loss: 0.5236 - val_accuracy: 0.8762\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5415 - accuracy: 0.8669 - val_loss: 0.5100 - val_accuracy: 0.8783\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5286 - accuracy: 0.8690 - val_loss: 0.4981 - val_accuracy: 0.8805\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5172 - accuracy: 0.8706 - val_loss: 0.4876 - val_accuracy: 0.8823\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.5070 - accuracy: 0.8723 - val_loss: 0.4781 - val_accuracy: 0.8845\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4978 - accuracy: 0.8740 - val_loss: 0.4695 - val_accuracy: 0.8856\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4895 - accuracy: 0.8753 - val_loss: 0.4619 - val_accuracy: 0.8867\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4820 - accuracy: 0.8767 - val_loss: 0.4548 - val_accuracy: 0.8876\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4751 - accuracy: 0.8778 - val_loss: 0.4484 - val_accuracy: 0.8886\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.4687 - accuracy: 0.8790 - val_loss: 0.4424 - val_accuracy: 0.8895\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4628 - accuracy: 0.8805 - val_loss: 0.4369 - val_accuracy: 0.8901\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4574 - accuracy: 0.8813 - val_loss: 0.4318 - val_accuracy: 0.8904\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4524 - accuracy: 0.8822 - val_loss: 0.4270 - val_accuracy: 0.8914\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4476 - accuracy: 0.8829 - val_loss: 0.4227 - val_accuracy: 0.8922\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4432 - accuracy: 0.8839 - val_loss: 0.4186 - val_accuracy: 0.8929\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4390 - accuracy: 0.8845 - val_loss: 0.4147 - val_accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4351 - accuracy: 0.8852 - val_loss: 0.4111 - val_accuracy: 0.8943\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4314 - accuracy: 0.8861 - val_loss: 0.4076 - val_accuracy: 0.8943\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4279 - accuracy: 0.8865 - val_loss: 0.4043 - val_accuracy: 0.8952\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4246 - accuracy: 0.8875 - val_loss: 0.4013 - val_accuracy: 0.8954\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4215 - accuracy: 0.8881 - val_loss: 0.3983 - val_accuracy: 0.8958\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4185 - accuracy: 0.8888 - val_loss: 0.3955 - val_accuracy: 0.8965\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4157 - accuracy: 0.8895 - val_loss: 0.3928 - val_accuracy: 0.8971\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4130 - accuracy: 0.8899 - val_loss: 0.3903 - val_accuracy: 0.8977\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4104 - accuracy: 0.8905 - val_loss: 0.3880 - val_accuracy: 0.8982\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4079 - accuracy: 0.8911 - val_loss: 0.3857 - val_accuracy: 0.8979\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4055 - accuracy: 0.8913 - val_loss: 0.3835 - val_accuracy: 0.8983\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4033 - accuracy: 0.8915 - val_loss: 0.3814 - val_accuracy: 0.8988\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4011 - accuracy: 0.8918 - val_loss: 0.3794 - val_accuracy: 0.8994\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3990 - accuracy: 0.8923 - val_loss: 0.3773 - val_accuracy: 0.8994\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3970 - accuracy: 0.8925 - val_loss: 0.3754 - val_accuracy: 0.8998\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3950 - accuracy: 0.8930 - val_loss: 0.3736 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3931 - accuracy: 0.8934 - val_loss: 0.3719 - val_accuracy: 0.9005\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3913 - accuracy: 0.8937 - val_loss: 0.3703 - val_accuracy: 0.9014\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3896 - accuracy: 0.8942 - val_loss: 0.3687 - val_accuracy: 0.9020\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3879 - accuracy: 0.8945 - val_loss: 0.3671 - val_accuracy: 0.9024\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3862 - accuracy: 0.8947 - val_loss: 0.3656 - val_accuracy: 0.9027\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3846 - accuracy: 0.8950 - val_loss: 0.3642 - val_accuracy: 0.9031\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3831 - accuracy: 0.8954 - val_loss: 0.3628 - val_accuracy: 0.9033\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3816 - accuracy: 0.8959 - val_loss: 0.3614 - val_accuracy: 0.9039\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3802 - accuracy: 0.8963 - val_loss: 0.3601 - val_accuracy: 0.9045\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3788 - accuracy: 0.8966 - val_loss: 0.3588 - val_accuracy: 0.9043\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3774 - accuracy: 0.8968 - val_loss: 0.3576 - val_accuracy: 0.9047\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3761 - accuracy: 0.8972 - val_loss: 0.3563 - val_accuracy: 0.9052\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3748 - accuracy: 0.8972 - val_loss: 0.3552 - val_accuracy: 0.9052\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3736 - accuracy: 0.8977 - val_loss: 0.3541 - val_accuracy: 0.9057\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3724 - accuracy: 0.8980 - val_loss: 0.3530 - val_accuracy: 0.9054\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3712 - accuracy: 0.8982 - val_loss: 0.3519 - val_accuracy: 0.9060\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3700 - accuracy: 0.8986 - val_loss: 0.3508 - val_accuracy: 0.9063\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3689 - accuracy: 0.8988 - val_loss: 0.3499 - val_accuracy: 0.9067\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3678 - accuracy: 0.8990 - val_loss: 0.3489 - val_accuracy: 0.9064\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3667 - accuracy: 0.8993 - val_loss: 0.3479 - val_accuracy: 0.9071\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3657 - accuracy: 0.8996 - val_loss: 0.3469 - val_accuracy: 0.9071\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3647 - accuracy: 0.8997 - val_loss: 0.3461 - val_accuracy: 0.9071\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3637 - accuracy: 0.9001 - val_loss: 0.3451 - val_accuracy: 0.9070\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3627 - accuracy: 0.9002 - val_loss: 0.3444 - val_accuracy: 0.9074\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3618 - accuracy: 0.9001 - val_loss: 0.3434 - val_accuracy: 0.9071\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3608 - accuracy: 0.9007 - val_loss: 0.3426 - val_accuracy: 0.9075\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3599 - accuracy: 0.9009 - val_loss: 0.3417 - val_accuracy: 0.9070\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3590 - accuracy: 0.9011 - val_loss: 0.3410 - val_accuracy: 0.9075\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3582 - accuracy: 0.9015 - val_loss: 0.3403 - val_accuracy: 0.9077\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3573 - accuracy: 0.9016 - val_loss: 0.3394 - val_accuracy: 0.9078\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3565 - accuracy: 0.9019 - val_loss: 0.3387 - val_accuracy: 0.9081\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3557 - accuracy: 0.9021 - val_loss: 0.3379 - val_accuracy: 0.9084\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3548 - accuracy: 0.9022 - val_loss: 0.3373 - val_accuracy: 0.9087\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3541 - accuracy: 0.9024 - val_loss: 0.3365 - val_accuracy: 0.9089\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.3533 - accuracy: 0.9026 - val_loss: 0.3358 - val_accuracy: 0.9091\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3526 - accuracy: 0.9030 - val_loss: 0.3352 - val_accuracy: 0.9090\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3518 - accuracy: 0.9030 - val_loss: 0.3346 - val_accuracy: 0.9093\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3511 - accuracy: 0.9033 - val_loss: 0.3339 - val_accuracy: 0.9094\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3504 - accuracy: 0.9033 - val_loss: 0.3333 - val_accuracy: 0.9099\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3497 - accuracy: 0.9036 - val_loss: 0.3327 - val_accuracy: 0.9096\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3490 - accuracy: 0.9037 - val_loss: 0.3321 - val_accuracy: 0.9098\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3483 - accuracy: 0.9038 - val_loss: 0.3315 - val_accuracy: 0.9100\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3476 - accuracy: 0.9041 - val_loss: 0.3309 - val_accuracy: 0.9100\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3470 - accuracy: 0.9042 - val_loss: 0.3304 - val_accuracy: 0.9096\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3464 - accuracy: 0.9044 - val_loss: 0.3297 - val_accuracy: 0.9102\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3457 - accuracy: 0.9043 - val_loss: 0.3293 - val_accuracy: 0.9099\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3451 - accuracy: 0.9046 - val_loss: 0.3287 - val_accuracy: 0.9101\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3445 - accuracy: 0.9050 - val_loss: 0.3282 - val_accuracy: 0.9100\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3439 - accuracy: 0.9050 - val_loss: 0.3276 - val_accuracy: 0.9100\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3433 - accuracy: 0.9052 - val_loss: 0.3271 - val_accuracy: 0.9101\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3427 - accuracy: 0.9053 - val_loss: 0.3267 - val_accuracy: 0.9107\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3422 - accuracy: 0.9056 - val_loss: 0.3261 - val_accuracy: 0.9103\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3416 - accuracy: 0.9057 - val_loss: 0.3256 - val_accuracy: 0.9106\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3410 - accuracy: 0.9060 - val_loss: 0.3252 - val_accuracy: 0.9102\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3405 - accuracy: 0.9061 - val_loss: 0.3247 - val_accuracy: 0.9107\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3399 - accuracy: 0.9064 - val_loss: 0.3242 - val_accuracy: 0.9109\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3394 - accuracy: 0.9063 - val_loss: 0.3238 - val_accuracy: 0.9110\n",
      "Total compute time to train model_2c was: 44.54 seconds\n",
      "Training Accuracy: 0.9063\n",
      "Test Accuracy: 0.9110\n",
      "Training Loss: 0.3394\n",
      "Test Loss: 0.3238\n"
     ]
    }
   ],
   "source": [
    "#Single layer perceptron \n",
    "#model_2c uses batch size of 512\n",
    "model_2c = Sequential()\n",
    "model_2c.add(Dense(units=10, activation='softmax', input_shape=(784,))) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_2c.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_2c_history = model_2c.fit(x=X_train, y=y_train, batch_size=512, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_2c was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_2c_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_2c_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_2c_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_2c_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Investigating Effect of Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1563 - accuracy: 0.3993 - val_loss: 1.9343 - val_accuracy: 0.5892\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.7806 - accuracy: 0.6352 - val_loss: 1.6124 - val_accuracy: 0.6958\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4868 - accuracy: 0.7017 - val_loss: 1.3443 - val_accuracy: 0.7476\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2549 - accuracy: 0.7513 - val_loss: 1.1438 - val_accuracy: 0.7729\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0838 - accuracy: 0.7801 - val_loss: 0.9973 - val_accuracy: 0.8036\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.9580 - accuracy: 0.8042 - val_loss: 0.8887 - val_accuracy: 0.8258\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.8631 - accuracy: 0.8225 - val_loss: 0.8056 - val_accuracy: 0.8394\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.7895 - accuracy: 0.8351 - val_loss: 0.7404 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.7306 - accuracy: 0.8445 - val_loss: 0.6874 - val_accuracy: 0.8579\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.6824 - accuracy: 0.8530 - val_loss: 0.6436 - val_accuracy: 0.8649\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6422 - accuracy: 0.8590 - val_loss: 0.6070 - val_accuracy: 0.8722\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6082 - accuracy: 0.8646 - val_loss: 0.5758 - val_accuracy: 0.8756\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.5791 - accuracy: 0.8692 - val_loss: 0.5489 - val_accuracy: 0.8794\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.5539 - accuracy: 0.8723 - val_loss: 0.5256 - val_accuracy: 0.8836\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5319 - accuracy: 0.8754 - val_loss: 0.5055 - val_accuracy: 0.8861\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5125 - accuracy: 0.8779 - val_loss: 0.4874 - val_accuracy: 0.8895\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4954 - accuracy: 0.8804 - val_loss: 0.4716 - val_accuracy: 0.8915\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4802 - accuracy: 0.8827 - val_loss: 0.4573 - val_accuracy: 0.8928\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4666 - accuracy: 0.8845 - val_loss: 0.4446 - val_accuracy: 0.8940\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4543 - accuracy: 0.8868 - val_loss: 0.4332 - val_accuracy: 0.8956\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4432 - accuracy: 0.8884 - val_loss: 0.4229 - val_accuracy: 0.8971\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4331 - accuracy: 0.8905 - val_loss: 0.4135 - val_accuracy: 0.8982\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4239 - accuracy: 0.8915 - val_loss: 0.4052 - val_accuracy: 0.8997\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4155 - accuracy: 0.8930 - val_loss: 0.3971 - val_accuracy: 0.9014\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4078 - accuracy: 0.8943 - val_loss: 0.3899 - val_accuracy: 0.9034\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4007 - accuracy: 0.8957 - val_loss: 0.3833 - val_accuracy: 0.9030\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3940 - accuracy: 0.8969 - val_loss: 0.3773 - val_accuracy: 0.9046\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3878 - accuracy: 0.8977 - val_loss: 0.3716 - val_accuracy: 0.9053\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3821 - accuracy: 0.8987 - val_loss: 0.3663 - val_accuracy: 0.9053\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3768 - accuracy: 0.8996 - val_loss: 0.3612 - val_accuracy: 0.9063\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3717 - accuracy: 0.9007 - val_loss: 0.3566 - val_accuracy: 0.9071\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3670 - accuracy: 0.9017 - val_loss: 0.3523 - val_accuracy: 0.9075\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3625 - accuracy: 0.9026 - val_loss: 0.3480 - val_accuracy: 0.9090\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3583 - accuracy: 0.9032 - val_loss: 0.3442 - val_accuracy: 0.9091\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3543 - accuracy: 0.9040 - val_loss: 0.3406 - val_accuracy: 0.9103\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3505 - accuracy: 0.9047 - val_loss: 0.3370 - val_accuracy: 0.9110\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3469 - accuracy: 0.9054 - val_loss: 0.3336 - val_accuracy: 0.9117\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3434 - accuracy: 0.9061 - val_loss: 0.3305 - val_accuracy: 0.9123\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3402 - accuracy: 0.9067 - val_loss: 0.3275 - val_accuracy: 0.9130\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3370 - accuracy: 0.9075 - val_loss: 0.3247 - val_accuracy: 0.9133\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3341 - accuracy: 0.9078 - val_loss: 0.3219 - val_accuracy: 0.9142\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3312 - accuracy: 0.9086 - val_loss: 0.3194 - val_accuracy: 0.9147\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3284 - accuracy: 0.9093 - val_loss: 0.3168 - val_accuracy: 0.9151\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3257 - accuracy: 0.9100 - val_loss: 0.3144 - val_accuracy: 0.9159\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3231 - accuracy: 0.9106 - val_loss: 0.3120 - val_accuracy: 0.9161\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3207 - accuracy: 0.9114 - val_loss: 0.3098 - val_accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3183 - accuracy: 0.9117 - val_loss: 0.3076 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3159 - accuracy: 0.9121 - val_loss: 0.3054 - val_accuracy: 0.9173\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3137 - accuracy: 0.9127 - val_loss: 0.3035 - val_accuracy: 0.9187\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3115 - accuracy: 0.9132 - val_loss: 0.3016 - val_accuracy: 0.9189\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3094 - accuracy: 0.9137 - val_loss: 0.2995 - val_accuracy: 0.9195\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3074 - accuracy: 0.9141 - val_loss: 0.2978 - val_accuracy: 0.9195\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3054 - accuracy: 0.9147 - val_loss: 0.2959 - val_accuracy: 0.9198\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3035 - accuracy: 0.9150 - val_loss: 0.2943 - val_accuracy: 0.9206\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3016 - accuracy: 0.9150 - val_loss: 0.2926 - val_accuracy: 0.9206\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2998 - accuracy: 0.9155 - val_loss: 0.2908 - val_accuracy: 0.9212\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2980 - accuracy: 0.9164 - val_loss: 0.2894 - val_accuracy: 0.9215\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2962 - accuracy: 0.9167 - val_loss: 0.2877 - val_accuracy: 0.9225\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2945 - accuracy: 0.9170 - val_loss: 0.2862 - val_accuracy: 0.9222\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2929 - accuracy: 0.9173 - val_loss: 0.2847 - val_accuracy: 0.9228\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2913 - accuracy: 0.9179 - val_loss: 0.2833 - val_accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2897 - accuracy: 0.9183 - val_loss: 0.2819 - val_accuracy: 0.9237\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2881 - accuracy: 0.9186 - val_loss: 0.2805 - val_accuracy: 0.9239\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2866 - accuracy: 0.9191 - val_loss: 0.2792 - val_accuracy: 0.9241\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2851 - accuracy: 0.9194 - val_loss: 0.2778 - val_accuracy: 0.9241\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2837 - accuracy: 0.9200 - val_loss: 0.2765 - val_accuracy: 0.9245\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2822 - accuracy: 0.9204 - val_loss: 0.2752 - val_accuracy: 0.9240\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2808 - accuracy: 0.9208 - val_loss: 0.2740 - val_accuracy: 0.9253\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2795 - accuracy: 0.9209 - val_loss: 0.2727 - val_accuracy: 0.9249\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2781 - accuracy: 0.9215 - val_loss: 0.2716 - val_accuracy: 0.9254\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2768 - accuracy: 0.9215 - val_loss: 0.2703 - val_accuracy: 0.9255\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2755 - accuracy: 0.9220 - val_loss: 0.2692 - val_accuracy: 0.9254\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2742 - accuracy: 0.9222 - val_loss: 0.2682 - val_accuracy: 0.9259\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2729 - accuracy: 0.9225 - val_loss: 0.2670 - val_accuracy: 0.9261\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2717 - accuracy: 0.9230 - val_loss: 0.2659 - val_accuracy: 0.9262\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2705 - accuracy: 0.9233 - val_loss: 0.2648 - val_accuracy: 0.9263\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2693 - accuracy: 0.9238 - val_loss: 0.2638 - val_accuracy: 0.9262\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2681 - accuracy: 0.9241 - val_loss: 0.2627 - val_accuracy: 0.9267\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2670 - accuracy: 0.9244 - val_loss: 0.2616 - val_accuracy: 0.9271\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2658 - accuracy: 0.9246 - val_loss: 0.2606 - val_accuracy: 0.9274\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2647 - accuracy: 0.9250 - val_loss: 0.2596 - val_accuracy: 0.9280\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2636 - accuracy: 0.9253 - val_loss: 0.2587 - val_accuracy: 0.9277\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2625 - accuracy: 0.9255 - val_loss: 0.2577 - val_accuracy: 0.9277\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2614 - accuracy: 0.9255 - val_loss: 0.2567 - val_accuracy: 0.9283\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2604 - accuracy: 0.9262 - val_loss: 0.2558 - val_accuracy: 0.9284\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2593 - accuracy: 0.9262 - val_loss: 0.2549 - val_accuracy: 0.9291\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2583 - accuracy: 0.9266 - val_loss: 0.2540 - val_accuracy: 0.9292\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2573 - accuracy: 0.9272 - val_loss: 0.2529 - val_accuracy: 0.9295\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2563 - accuracy: 0.9273 - val_loss: 0.2522 - val_accuracy: 0.9299\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2553 - accuracy: 0.9276 - val_loss: 0.2513 - val_accuracy: 0.9300\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2543 - accuracy: 0.9280 - val_loss: 0.2505 - val_accuracy: 0.9309\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2533 - accuracy: 0.9283 - val_loss: 0.2496 - val_accuracy: 0.9307\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2524 - accuracy: 0.9285 - val_loss: 0.2487 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2514 - accuracy: 0.9289 - val_loss: 0.2478 - val_accuracy: 0.9312\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2505 - accuracy: 0.9290 - val_loss: 0.2470 - val_accuracy: 0.9309\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2496 - accuracy: 0.9293 - val_loss: 0.2463 - val_accuracy: 0.9315\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2487 - accuracy: 0.9297 - val_loss: 0.2454 - val_accuracy: 0.9312\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2478 - accuracy: 0.9299 - val_loss: 0.2446 - val_accuracy: 0.9317\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2469 - accuracy: 0.9301 - val_loss: 0.2438 - val_accuracy: 0.9318\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2460 - accuracy: 0.9303 - val_loss: 0.2431 - val_accuracy: 0.9318\n",
      "Total compute time to train model_3a was: 99.98 seconds\n",
      "Training Accuracy: 0.9303\n",
      "Test Accuracy: 0.9318\n",
      "Training Loss: 0.2460\n",
      "Test Loss: 0.2431\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "#model_3a uses 32 nodes in the hidden layer\n",
    "model_3a = Sequential()\n",
    "model_3a.add(Dense(units=32, activation='sigmoid', input_shape=(784,))) \n",
    "model_3a.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_3a.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_3a_history = model_3a.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_3a was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_3a_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_3a_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_3a_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_3a_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.0333 - accuracy: 0.4931 - val_loss: 1.7722 - val_accuracy: 0.6806\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5835 - accuracy: 0.7258 - val_loss: 1.3829 - val_accuracy: 0.7720\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2580 - accuracy: 0.7815 - val_loss: 1.1120 - val_accuracy: 0.8111\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0360 - accuracy: 0.8105 - val_loss: 0.9317 - val_accuracy: 0.8233\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8866 - accuracy: 0.8270 - val_loss: 0.8086 - val_accuracy: 0.8451\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7829 - accuracy: 0.8398 - val_loss: 0.7218 - val_accuracy: 0.8554\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7079 - accuracy: 0.8486 - val_loss: 0.6578 - val_accuracy: 0.8628\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6514 - accuracy: 0.8557 - val_loss: 0.6083 - val_accuracy: 0.8703\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6074 - accuracy: 0.8624 - val_loss: 0.5697 - val_accuracy: 0.8745\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5722 - accuracy: 0.8674 - val_loss: 0.5382 - val_accuracy: 0.8783\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5433 - accuracy: 0.8715 - val_loss: 0.5119 - val_accuracy: 0.8818\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5192 - accuracy: 0.8745 - val_loss: 0.4902 - val_accuracy: 0.8853\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4988 - accuracy: 0.8776 - val_loss: 0.4715 - val_accuracy: 0.8869\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4812 - accuracy: 0.8798 - val_loss: 0.4553 - val_accuracy: 0.8891\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4659 - accuracy: 0.8822 - val_loss: 0.4414 - val_accuracy: 0.8913\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4526 - accuracy: 0.8845 - val_loss: 0.4291 - val_accuracy: 0.8932\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4407 - accuracy: 0.8864 - val_loss: 0.4182 - val_accuracy: 0.8953\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4302 - accuracy: 0.8884 - val_loss: 0.4086 - val_accuracy: 0.8970\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4207 - accuracy: 0.8904 - val_loss: 0.4000 - val_accuracy: 0.8997\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4122 - accuracy: 0.8919 - val_loss: 0.3920 - val_accuracy: 0.8998\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4044 - accuracy: 0.8933 - val_loss: 0.3848 - val_accuracy: 0.9004\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3973 - accuracy: 0.8945 - val_loss: 0.3785 - val_accuracy: 0.9018\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3908 - accuracy: 0.8957 - val_loss: 0.3723 - val_accuracy: 0.9021\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3848 - accuracy: 0.8966 - val_loss: 0.3667 - val_accuracy: 0.9033\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3792 - accuracy: 0.8975 - val_loss: 0.3617 - val_accuracy: 0.9041\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3740 - accuracy: 0.8984 - val_loss: 0.3570 - val_accuracy: 0.9043\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3692 - accuracy: 0.8991 - val_loss: 0.3524 - val_accuracy: 0.9051\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3646 - accuracy: 0.9002 - val_loss: 0.3483 - val_accuracy: 0.9056\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3603 - accuracy: 0.9010 - val_loss: 0.3447 - val_accuracy: 0.9057\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3563 - accuracy: 0.9018 - val_loss: 0.3407 - val_accuracy: 0.9071\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3526 - accuracy: 0.9025 - val_loss: 0.3371 - val_accuracy: 0.9082\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3490 - accuracy: 0.9033 - val_loss: 0.3340 - val_accuracy: 0.9081\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3455 - accuracy: 0.9041 - val_loss: 0.3308 - val_accuracy: 0.9094\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3423 - accuracy: 0.9047 - val_loss: 0.3279 - val_accuracy: 0.9096\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3392 - accuracy: 0.9058 - val_loss: 0.3253 - val_accuracy: 0.9114\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3362 - accuracy: 0.9063 - val_loss: 0.3223 - val_accuracy: 0.9113\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3334 - accuracy: 0.9070 - val_loss: 0.3200 - val_accuracy: 0.9117\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3307 - accuracy: 0.9076 - val_loss: 0.3174 - val_accuracy: 0.9131\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3280 - accuracy: 0.9082 - val_loss: 0.3150 - val_accuracy: 0.9136\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3256 - accuracy: 0.9087 - val_loss: 0.3129 - val_accuracy: 0.9132\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3231 - accuracy: 0.9092 - val_loss: 0.3106 - val_accuracy: 0.9146\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3207 - accuracy: 0.9099 - val_loss: 0.3083 - val_accuracy: 0.9140\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3185 - accuracy: 0.9103 - val_loss: 0.3065 - val_accuracy: 0.9148\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3163 - accuracy: 0.9110 - val_loss: 0.3045 - val_accuracy: 0.9153\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3142 - accuracy: 0.9118 - val_loss: 0.3027 - val_accuracy: 0.9154\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3122 - accuracy: 0.9122 - val_loss: 0.3008 - val_accuracy: 0.9164\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3102 - accuracy: 0.9125 - val_loss: 0.2992 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3083 - accuracy: 0.9129 - val_loss: 0.2973 - val_accuracy: 0.9170\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3064 - accuracy: 0.9134 - val_loss: 0.2957 - val_accuracy: 0.9173\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3046 - accuracy: 0.9137 - val_loss: 0.2940 - val_accuracy: 0.9174\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3028 - accuracy: 0.9142 - val_loss: 0.2926 - val_accuracy: 0.9185\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3011 - accuracy: 0.9150 - val_loss: 0.2911 - val_accuracy: 0.9179\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2993 - accuracy: 0.9150 - val_loss: 0.2894 - val_accuracy: 0.9190\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2977 - accuracy: 0.9157 - val_loss: 0.2881 - val_accuracy: 0.9187\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2961 - accuracy: 0.9159 - val_loss: 0.2866 - val_accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2945 - accuracy: 0.9165 - val_loss: 0.2851 - val_accuracy: 0.9197\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2930 - accuracy: 0.9170 - val_loss: 0.2837 - val_accuracy: 0.9200\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2915 - accuracy: 0.9174 - val_loss: 0.2826 - val_accuracy: 0.9202\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2900 - accuracy: 0.9176 - val_loss: 0.2811 - val_accuracy: 0.9208\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2886 - accuracy: 0.9183 - val_loss: 0.2799 - val_accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2872 - accuracy: 0.9183 - val_loss: 0.2788 - val_accuracy: 0.9212\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2858 - accuracy: 0.9189 - val_loss: 0.2775 - val_accuracy: 0.9217\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2844 - accuracy: 0.9191 - val_loss: 0.2765 - val_accuracy: 0.9216\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2831 - accuracy: 0.9196 - val_loss: 0.2753 - val_accuracy: 0.9222\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2818 - accuracy: 0.9200 - val_loss: 0.2742 - val_accuracy: 0.9215\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2805 - accuracy: 0.9201 - val_loss: 0.2729 - val_accuracy: 0.9222\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2792 - accuracy: 0.9203 - val_loss: 0.2719 - val_accuracy: 0.9221\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2779 - accuracy: 0.9208 - val_loss: 0.2707 - val_accuracy: 0.9219\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2767 - accuracy: 0.9211 - val_loss: 0.2695 - val_accuracy: 0.9226\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2755 - accuracy: 0.9214 - val_loss: 0.2687 - val_accuracy: 0.9225\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2743 - accuracy: 0.9217 - val_loss: 0.2675 - val_accuracy: 0.9230\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2731 - accuracy: 0.9221 - val_loss: 0.2666 - val_accuracy: 0.9230\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2720 - accuracy: 0.9223 - val_loss: 0.2656 - val_accuracy: 0.9236\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2708 - accuracy: 0.9223 - val_loss: 0.2645 - val_accuracy: 0.9235\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2697 - accuracy: 0.9230 - val_loss: 0.2635 - val_accuracy: 0.9239\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2686 - accuracy: 0.9235 - val_loss: 0.2627 - val_accuracy: 0.9239\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2675 - accuracy: 0.9237 - val_loss: 0.2617 - val_accuracy: 0.9239\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2664 - accuracy: 0.9241 - val_loss: 0.2607 - val_accuracy: 0.9249\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2653 - accuracy: 0.9241 - val_loss: 0.2598 - val_accuracy: 0.9255\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2643 - accuracy: 0.9245 - val_loss: 0.2588 - val_accuracy: 0.9253\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2632 - accuracy: 0.9248 - val_loss: 0.2578 - val_accuracy: 0.9261\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2622 - accuracy: 0.9251 - val_loss: 0.2573 - val_accuracy: 0.9259\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2612 - accuracy: 0.9253 - val_loss: 0.2562 - val_accuracy: 0.9262\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2602 - accuracy: 0.9257 - val_loss: 0.2555 - val_accuracy: 0.9266\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2592 - accuracy: 0.9258 - val_loss: 0.2546 - val_accuracy: 0.9272\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2582 - accuracy: 0.9259 - val_loss: 0.2536 - val_accuracy: 0.9271\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2572 - accuracy: 0.9264 - val_loss: 0.2529 - val_accuracy: 0.9276\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2563 - accuracy: 0.9268 - val_loss: 0.2520 - val_accuracy: 0.9275\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2553 - accuracy: 0.9270 - val_loss: 0.2511 - val_accuracy: 0.9283\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2544 - accuracy: 0.9272 - val_loss: 0.2504 - val_accuracy: 0.9285\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2534 - accuracy: 0.9275 - val_loss: 0.2494 - val_accuracy: 0.9287\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2525 - accuracy: 0.9279 - val_loss: 0.2487 - val_accuracy: 0.9291\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2516 - accuracy: 0.9282 - val_loss: 0.2478 - val_accuracy: 0.9292\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2507 - accuracy: 0.9285 - val_loss: 0.2472 - val_accuracy: 0.9291\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2498 - accuracy: 0.9286 - val_loss: 0.2462 - val_accuracy: 0.9294\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2489 - accuracy: 0.9290 - val_loss: 0.2456 - val_accuracy: 0.9304\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2480 - accuracy: 0.9293 - val_loss: 0.2448 - val_accuracy: 0.9301\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2471 - accuracy: 0.9294 - val_loss: 0.2439 - val_accuracy: 0.9309\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2463 - accuracy: 0.9295 - val_loss: 0.2433 - val_accuracy: 0.9307\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2455 - accuracy: 0.9298 - val_loss: 0.2425 - val_accuracy: 0.9314\n",
      "Total compute time to train model_3b was: 118.63 seconds\n",
      "Training Accuracy: 0.9298\n",
      "Test Accuracy: 0.9314\n",
      "Training Loss: 0.2455\n",
      "Test Loss: 0.2425\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "#model_3b uses 64 nodes in the hidden layer\n",
    "model_3b = Sequential()\n",
    "model_3b.add(Dense(units=64, activation='sigmoid', input_shape=(784,))) \n",
    "model_3b.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_3b.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_3b_history = model_3b.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_3b was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_3b_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_3b_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_3b_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_3b_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.0550 - accuracy: 0.4936 - val_loss: 1.7780 - val_accuracy: 0.7015\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.5583 - accuracy: 0.7246 - val_loss: 1.3385 - val_accuracy: 0.7766\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.1978 - accuracy: 0.7852 - val_loss: 1.0471 - val_accuracy: 0.8117\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.9674 - accuracy: 0.8164 - val_loss: 0.8651 - val_accuracy: 0.8387\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.8211 - accuracy: 0.8348 - val_loss: 0.7472 - val_accuracy: 0.8490\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.7233 - accuracy: 0.8472 - val_loss: 0.6660 - val_accuracy: 0.8581\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.6541 - accuracy: 0.8550 - val_loss: 0.6071 - val_accuracy: 0.8653\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.6028 - accuracy: 0.8615 - val_loss: 0.5627 - val_accuracy: 0.8711\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.5635 - accuracy: 0.8664 - val_loss: 0.5280 - val_accuracy: 0.8756\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.5322 - accuracy: 0.8718 - val_loss: 0.5003 - val_accuracy: 0.8796\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.5069 - accuracy: 0.8753 - val_loss: 0.4775 - val_accuracy: 0.8835\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4859 - accuracy: 0.8789 - val_loss: 0.4586 - val_accuracy: 0.8868\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4682 - accuracy: 0.8812 - val_loss: 0.4426 - val_accuracy: 0.8899\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4531 - accuracy: 0.8835 - val_loss: 0.4289 - val_accuracy: 0.8919\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4400 - accuracy: 0.8858 - val_loss: 0.4168 - val_accuracy: 0.8936\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4285 - accuracy: 0.8881 - val_loss: 0.4064 - val_accuracy: 0.8944\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4185 - accuracy: 0.8890 - val_loss: 0.3971 - val_accuracy: 0.8960\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4095 - accuracy: 0.8904 - val_loss: 0.3889 - val_accuracy: 0.8969\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4015 - accuracy: 0.8922 - val_loss: 0.3818 - val_accuracy: 0.8985\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3942 - accuracy: 0.8937 - val_loss: 0.3751 - val_accuracy: 0.8989\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3876 - accuracy: 0.8947 - val_loss: 0.3691 - val_accuracy: 0.8996\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3816 - accuracy: 0.8958 - val_loss: 0.3638 - val_accuracy: 0.9019\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3761 - accuracy: 0.8972 - val_loss: 0.3587 - val_accuracy: 0.9025\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3710 - accuracy: 0.8978 - val_loss: 0.3539 - val_accuracy: 0.9043\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3662 - accuracy: 0.8989 - val_loss: 0.3498 - val_accuracy: 0.9038\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3618 - accuracy: 0.8999 - val_loss: 0.3461 - val_accuracy: 0.9055\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3578 - accuracy: 0.9002 - val_loss: 0.3420 - val_accuracy: 0.9060\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3540 - accuracy: 0.9009 - val_loss: 0.3385 - val_accuracy: 0.9064\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3503 - accuracy: 0.9017 - val_loss: 0.3351 - val_accuracy: 0.9071\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3470 - accuracy: 0.9029 - val_loss: 0.3320 - val_accuracy: 0.9077\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3438 - accuracy: 0.9030 - val_loss: 0.3292 - val_accuracy: 0.9085\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3407 - accuracy: 0.9042 - val_loss: 0.3267 - val_accuracy: 0.9092\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3378 - accuracy: 0.9046 - val_loss: 0.3236 - val_accuracy: 0.9096\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3351 - accuracy: 0.9054 - val_loss: 0.3213 - val_accuracy: 0.9099\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3325 - accuracy: 0.9061 - val_loss: 0.3190 - val_accuracy: 0.9104\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3300 - accuracy: 0.9067 - val_loss: 0.3170 - val_accuracy: 0.9110\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3277 - accuracy: 0.9074 - val_loss: 0.3148 - val_accuracy: 0.9113\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3254 - accuracy: 0.9075 - val_loss: 0.3127 - val_accuracy: 0.9123\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3232 - accuracy: 0.9082 - val_loss: 0.3108 - val_accuracy: 0.9130\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3211 - accuracy: 0.9086 - val_loss: 0.3091 - val_accuracy: 0.9129\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3191 - accuracy: 0.9091 - val_loss: 0.3071 - val_accuracy: 0.9143\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3171 - accuracy: 0.9097 - val_loss: 0.3053 - val_accuracy: 0.9141\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3152 - accuracy: 0.9104 - val_loss: 0.3037 - val_accuracy: 0.9145\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3134 - accuracy: 0.9106 - val_loss: 0.3021 - val_accuracy: 0.9152\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3116 - accuracy: 0.9111 - val_loss: 0.3007 - val_accuracy: 0.9152\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3099 - accuracy: 0.9114 - val_loss: 0.2990 - val_accuracy: 0.9153\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3082 - accuracy: 0.9122 - val_loss: 0.2976 - val_accuracy: 0.9160\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3066 - accuracy: 0.9127 - val_loss: 0.2961 - val_accuracy: 0.9165\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3050 - accuracy: 0.9128 - val_loss: 0.2951 - val_accuracy: 0.9156\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3035 - accuracy: 0.9133 - val_loss: 0.2934 - val_accuracy: 0.9173\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3020 - accuracy: 0.9142 - val_loss: 0.2922 - val_accuracy: 0.9168\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3005 - accuracy: 0.9138 - val_loss: 0.2909 - val_accuracy: 0.9177\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2991 - accuracy: 0.9145 - val_loss: 0.2897 - val_accuracy: 0.9180\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2977 - accuracy: 0.9147 - val_loss: 0.2883 - val_accuracy: 0.9182\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2963 - accuracy: 0.9154 - val_loss: 0.2871 - val_accuracy: 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2950 - accuracy: 0.9155 - val_loss: 0.2862 - val_accuracy: 0.9182\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2937 - accuracy: 0.9161 - val_loss: 0.2848 - val_accuracy: 0.9191\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2924 - accuracy: 0.9164 - val_loss: 0.2840 - val_accuracy: 0.9194\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2912 - accuracy: 0.9165 - val_loss: 0.2830 - val_accuracy: 0.9202\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2899 - accuracy: 0.9169 - val_loss: 0.2816 - val_accuracy: 0.9198\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2887 - accuracy: 0.9174 - val_loss: 0.2807 - val_accuracy: 0.9209\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2875 - accuracy: 0.9174 - val_loss: 0.2795 - val_accuracy: 0.9211\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2863 - accuracy: 0.9179 - val_loss: 0.2786 - val_accuracy: 0.9218\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2852 - accuracy: 0.9182 - val_loss: 0.2776 - val_accuracy: 0.9216\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2840 - accuracy: 0.9187 - val_loss: 0.2767 - val_accuracy: 0.9223\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2829 - accuracy: 0.9190 - val_loss: 0.2753 - val_accuracy: 0.9221\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2818 - accuracy: 0.9191 - val_loss: 0.2745 - val_accuracy: 0.9227\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2807 - accuracy: 0.9197 - val_loss: 0.2736 - val_accuracy: 0.9227\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2796 - accuracy: 0.9200 - val_loss: 0.2725 - val_accuracy: 0.9227\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2785 - accuracy: 0.9201 - val_loss: 0.2719 - val_accuracy: 0.9235\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2775 - accuracy: 0.9205 - val_loss: 0.2708 - val_accuracy: 0.9240\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.2765 - accuracy: 0.9209 - val_loss: 0.2700 - val_accuracy: 0.9237\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2754 - accuracy: 0.9209 - val_loss: 0.2693 - val_accuracy: 0.9242\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2744 - accuracy: 0.9216 - val_loss: 0.2682 - val_accuracy: 0.9247\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2734 - accuracy: 0.9219 - val_loss: 0.2675 - val_accuracy: 0.9253\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2724 - accuracy: 0.9219 - val_loss: 0.2665 - val_accuracy: 0.9252\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2714 - accuracy: 0.9224 - val_loss: 0.2658 - val_accuracy: 0.9254\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2704 - accuracy: 0.9226 - val_loss: 0.2648 - val_accuracy: 0.9255\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2694 - accuracy: 0.9230 - val_loss: 0.2639 - val_accuracy: 0.9258\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2684 - accuracy: 0.9231 - val_loss: 0.2630 - val_accuracy: 0.9259\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2675 - accuracy: 0.9233 - val_loss: 0.2625 - val_accuracy: 0.9261\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2665 - accuracy: 0.9237 - val_loss: 0.2615 - val_accuracy: 0.9269\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2656 - accuracy: 0.9237 - val_loss: 0.2606 - val_accuracy: 0.9267\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2647 - accuracy: 0.9244 - val_loss: 0.2598 - val_accuracy: 0.9264\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2637 - accuracy: 0.9242 - val_loss: 0.2593 - val_accuracy: 0.9275\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2628 - accuracy: 0.9249 - val_loss: 0.2583 - val_accuracy: 0.9270\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2619 - accuracy: 0.9253 - val_loss: 0.2572 - val_accuracy: 0.9269\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2610 - accuracy: 0.9254 - val_loss: 0.2567 - val_accuracy: 0.9274\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2600 - accuracy: 0.9256 - val_loss: 0.2558 - val_accuracy: 0.9273\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2592 - accuracy: 0.9259 - val_loss: 0.2550 - val_accuracy: 0.9272\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2583 - accuracy: 0.9262 - val_loss: 0.2543 - val_accuracy: 0.9277\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2574 - accuracy: 0.9265 - val_loss: 0.2537 - val_accuracy: 0.9284\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2565 - accuracy: 0.9268 - val_loss: 0.2527 - val_accuracy: 0.9283\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2557 - accuracy: 0.9271 - val_loss: 0.2520 - val_accuracy: 0.9279\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2548 - accuracy: 0.9275 - val_loss: 0.2513 - val_accuracy: 0.9284\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2539 - accuracy: 0.9275 - val_loss: 0.2504 - val_accuracy: 0.9289\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2530 - accuracy: 0.9280 - val_loss: 0.2498 - val_accuracy: 0.9283\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2522 - accuracy: 0.9281 - val_loss: 0.2494 - val_accuracy: 0.9294\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2513 - accuracy: 0.9285 - val_loss: 0.2482 - val_accuracy: 0.9293\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2505 - accuracy: 0.9287 - val_loss: 0.2475 - val_accuracy: 0.9296\n",
      "Total compute time to train model_3c was: 140.34 seconds\n",
      "Training Accuracy: 0.9287\n",
      "Test Accuracy: 0.9296\n",
      "Training Loss: 0.2505\n",
      "Test Loss: 0.2475\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "#model_3c uses 128 nodes in the hidden layer\n",
    "model_3c = Sequential()\n",
    "model_3c.add(Dense(units=128, activation='sigmoid', input_shape=(784,))) \n",
    "model_3c.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_3c.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_3c_history = model_3c.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_3c was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_3c_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_3c_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_3c_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_3c_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Investigating Effect of Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1387 - accuracy: 0.4304 - val_loss: 1.9476 - val_accuracy: 0.6522\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.7817 - accuracy: 0.6863 - val_loss: 1.6119 - val_accuracy: 0.7226\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.4762 - accuracy: 0.7372 - val_loss: 1.3341 - val_accuracy: 0.7683\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.2364 - accuracy: 0.7724 - val_loss: 1.1261 - val_accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0600 - accuracy: 0.7982 - val_loss: 0.9749 - val_accuracy: 0.8162\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.9309 - accuracy: 0.8158 - val_loss: 0.8635 - val_accuracy: 0.8339\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.8343 - accuracy: 0.8303 - val_loss: 0.7786 - val_accuracy: 0.8463\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7601 - accuracy: 0.8414 - val_loss: 0.7125 - val_accuracy: 0.8547\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7015 - accuracy: 0.8499 - val_loss: 0.6602 - val_accuracy: 0.8629\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6544 - accuracy: 0.8568 - val_loss: 0.6173 - val_accuracy: 0.8687\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6155 - accuracy: 0.8634 - val_loss: 0.5818 - val_accuracy: 0.8729\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5831 - accuracy: 0.8678 - val_loss: 0.5522 - val_accuracy: 0.8773\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.5557 - accuracy: 0.8719 - val_loss: 0.5270 - val_accuracy: 0.8825\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5324 - accuracy: 0.8753 - val_loss: 0.5052 - val_accuracy: 0.8850\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5122 - accuracy: 0.8778 - val_loss: 0.4865 - val_accuracy: 0.8880\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4946 - accuracy: 0.8809 - val_loss: 0.4702 - val_accuracy: 0.8899\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4791 - accuracy: 0.8828 - val_loss: 0.4557 - val_accuracy: 0.8921\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4654 - accuracy: 0.8851 - val_loss: 0.4429 - val_accuracy: 0.8932\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4532 - accuracy: 0.8870 - val_loss: 0.4316 - val_accuracy: 0.8951\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4422 - accuracy: 0.8888 - val_loss: 0.4213 - val_accuracy: 0.8963\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4323 - accuracy: 0.8904 - val_loss: 0.4120 - val_accuracy: 0.8978\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4233 - accuracy: 0.8914 - val_loss: 0.4037 - val_accuracy: 0.8988\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4151 - accuracy: 0.8930 - val_loss: 0.3960 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4076 - accuracy: 0.8937 - val_loss: 0.3890 - val_accuracy: 0.9004\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4007 - accuracy: 0.8953 - val_loss: 0.3823 - val_accuracy: 0.9023\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3942 - accuracy: 0.8965 - val_loss: 0.3765 - val_accuracy: 0.9026\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3883 - accuracy: 0.8973 - val_loss: 0.3708 - val_accuracy: 0.9040\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3827 - accuracy: 0.8984 - val_loss: 0.3658 - val_accuracy: 0.9041\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3775 - accuracy: 0.8992 - val_loss: 0.3608 - val_accuracy: 0.9054\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3727 - accuracy: 0.9001 - val_loss: 0.3562 - val_accuracy: 0.9061\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3680 - accuracy: 0.9003 - val_loss: 0.3521 - val_accuracy: 0.9075\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3637 - accuracy: 0.9014 - val_loss: 0.3479 - val_accuracy: 0.9079\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3596 - accuracy: 0.9016 - val_loss: 0.3443 - val_accuracy: 0.9086\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3558 - accuracy: 0.9029 - val_loss: 0.3406 - val_accuracy: 0.9095\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3521 - accuracy: 0.9032 - val_loss: 0.3371 - val_accuracy: 0.9103356\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3486 - accuracy: 0.9041 - val_loss: 0.3337 - val_accuracy: 0.9107\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3452 - accuracy: 0.9043 - val_loss: 0.3307 - val_accuracy: 0.9116\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3420 - accuracy: 0.9053 - val_loss: 0.3276 - val_accuracy: 0.9115\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3389 - accuracy: 0.9060 - val_loss: 0.3249 - val_accuracy: 0.9129\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3360 - accuracy: 0.9065 - val_loss: 0.3222 - val_accuracy: 0.9133\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3332 - accuracy: 0.9071 - val_loss: 0.3195 - val_accuracy: 0.9139\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3305 - accuracy: 0.9076 - val_loss: 0.3173 - val_accuracy: 0.9142\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3279 - accuracy: 0.9085 - val_loss: 0.3147 - val_accuracy: 0.9143\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3253 - accuracy: 0.9093 - val_loss: 0.3124 - val_accuracy: 0.9155\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3229 - accuracy: 0.9095 - val_loss: 0.3102 - val_accuracy: 0.9162\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3205 - accuracy: 0.9102 - val_loss: 0.3079 - val_accuracy: 0.9172\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3182 - accuracy: 0.9111 - val_loss: 0.3059 - val_accuracy: 0.9169\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3161 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.9178\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3139 - accuracy: 0.9121 - val_loss: 0.3019 - val_accuracy: 0.9182\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3119 - accuracy: 0.9127 - val_loss: 0.3000 - val_accuracy: 0.9183\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3098 - accuracy: 0.9130 - val_loss: 0.2983 - val_accuracy: 0.9192\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3079 - accuracy: 0.9138 - val_loss: 0.2965 - val_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3060 - accuracy: 0.9141 - val_loss: 0.2947 - val_accuracy: 0.9196\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3041 - accuracy: 0.9146 - val_loss: 0.2931 - val_accuracy: 0.9197\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3023 - accuracy: 0.9152 - val_loss: 0.2917 - val_accuracy: 0.9201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3006 - accuracy: 0.9154 - val_loss: 0.2898 - val_accuracy: 0.9202\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2988 - accuracy: 0.9161 - val_loss: 0.2884 - val_accuracy: 0.9206\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2972 - accuracy: 0.9164 - val_loss: 0.2869 - val_accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2955 - accuracy: 0.9169 - val_loss: 0.2855 - val_accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2939 - accuracy: 0.9172 - val_loss: 0.2840 - val_accuracy: 0.9215\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2923 - accuracy: 0.9176 - val_loss: 0.2827 - val_accuracy: 0.9220\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2908 - accuracy: 0.9180 - val_loss: 0.2813 - val_accuracy: 0.9225\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2893 - accuracy: 0.9183 - val_loss: 0.2799 - val_accuracy: 0.9234\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2878 - accuracy: 0.9187 - val_loss: 0.2786 - val_accuracy: 0.9241\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2864 - accuracy: 0.9192 - val_loss: 0.2773 - val_accuracy: 0.9236\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2850 - accuracy: 0.9195 - val_loss: 0.2761 - val_accuracy: 0.9247\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2836 - accuracy: 0.9200 - val_loss: 0.2748 - val_accuracy: 0.9243\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2822 - accuracy: 0.9203 - val_loss: 0.2735 - val_accuracy: 0.9253\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2809 - accuracy: 0.9204 - val_loss: 0.2724 - val_accuracy: 0.9254\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2796 - accuracy: 0.9210 - val_loss: 0.2713 - val_accuracy: 0.9255\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2783 - accuracy: 0.9212 - val_loss: 0.2701 - val_accuracy: 0.9260\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2770 - accuracy: 0.9216 - val_loss: 0.2690 - val_accuracy: 0.9257\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2758 - accuracy: 0.9216 - val_loss: 0.2681 - val_accuracy: 0.9263\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2746 - accuracy: 0.9218 - val_loss: 0.2670 - val_accuracy: 0.9264\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2734 - accuracy: 0.9223 - val_loss: 0.2659 - val_accuracy: 0.9273\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2722 - accuracy: 0.9226 - val_loss: 0.2647 - val_accuracy: 0.9271\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2710 - accuracy: 0.9228 - val_loss: 0.2638 - val_accuracy: 0.9269\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2699 - accuracy: 0.9232 - val_loss: 0.2627 - val_accuracy: 0.9271\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2687 - accuracy: 0.9238 - val_loss: 0.2617 - val_accuracy: 0.9275\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2676 - accuracy: 0.9237 - val_loss: 0.2609 - val_accuracy: 0.9283\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2665 - accuracy: 0.9239 - val_loss: 0.2597 - val_accuracy: 0.9284\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.2655 - accuracy: 0.9243 - val_loss: 0.2589 - val_accuracy: 0.9285\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2644 - accuracy: 0.9246 - val_loss: 0.2581 - val_accuracy: 0.9286\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2633 - accuracy: 0.9250 - val_loss: 0.2570 - val_accuracy: 0.9292\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2623 - accuracy: 0.9253 - val_loss: 0.2562 - val_accuracy: 0.9295\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2613 - accuracy: 0.9255 - val_loss: 0.2556 - val_accuracy: 0.9289\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2603 - accuracy: 0.9258 - val_loss: 0.2545 - val_accuracy: 0.9298\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2593 - accuracy: 0.9261 - val_loss: 0.2536 - val_accuracy: 0.9297\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2583 - accuracy: 0.9264 - val_loss: 0.2527 - val_accuracy: 0.9296\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2573 - accuracy: 0.9266 - val_loss: 0.2520 - val_accuracy: 0.9300\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2564 - accuracy: 0.9268 - val_loss: 0.2511 - val_accuracy: 0.9298\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2555 - accuracy: 0.9270 - val_loss: 0.2503 - val_accuracy: 0.9302\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2545 - accuracy: 0.9273 - val_loss: 0.2494 - val_accuracy: 0.9302\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2536 - accuracy: 0.9277 - val_loss: 0.2488 - val_accuracy: 0.9308\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2527 - accuracy: 0.9280 - val_loss: 0.2479 - val_accuracy: 0.9308\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2518 - accuracy: 0.9280 - val_loss: 0.2471 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2509 - accuracy: 0.9283 - val_loss: 0.2464 - val_accuracy: 0.9312\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2500 - accuracy: 0.9284 - val_loss: 0.2455 - val_accuracy: 0.9316\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2492 - accuracy: 0.9290 - val_loss: 0.2448 - val_accuracy: 0.9316\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2483 - accuracy: 0.9291 - val_loss: 0.2440 - val_accuracy: 0.9317\n",
      "Total compute time to train model_4a was: 105.26 seconds\n",
      "Training Accuracy: 0.9291\n",
      "Test Accuracy: 0.9317\n",
      "Training Loss: 0.2483\n",
      "Test Loss: 0.2440\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "#model_4a uses sigmoid as the activation function\n",
    "model_4a = Sequential()\n",
    "model_4a.add(Dense(units=32, activation='sigmoid', input_shape=(784,))) \n",
    "model_4a.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_4a.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_4a_history = model_4a.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_4a was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_4a_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_4a_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_4a_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_4a_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2000 - accuracy: 0.7068 - val_loss: 0.7629 - val_accuracy: 0.8345\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6638 - accuracy: 0.8484 - val_loss: 0.5562 - val_accuracy: 0.8728\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.5280 - accuracy: 0.8725 - val_loss: 0.4696 - val_accuracy: 0.8860\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4612 - accuracy: 0.8833 - val_loss: 0.4201 - val_accuracy: 0.8954\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4204 - accuracy: 0.8908 - val_loss: 0.3883 - val_accuracy: 0.9012\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3924 - accuracy: 0.8956 - val_loss: 0.3661 - val_accuracy: 0.9043\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3714 - accuracy: 0.9003 - val_loss: 0.3488 - val_accuracy: 0.9086\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3553 - accuracy: 0.9029 - val_loss: 0.3349 - val_accuracy: 0.9113\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3419 - accuracy: 0.9060 - val_loss: 0.3233 - val_accuracy: 0.9143\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3305 - accuracy: 0.9083 - val_loss: 0.3137 - val_accuracy: 0.9161\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3208 - accuracy: 0.9107 - val_loss: 0.3056 - val_accuracy: 0.9175\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3121 - accuracy: 0.9131 - val_loss: 0.2978 - val_accuracy: 0.9188\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3043 - accuracy: 0.9150 - val_loss: 0.2912 - val_accuracy: 0.9206\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2973 - accuracy: 0.9169 - val_loss: 0.2854 - val_accuracy: 0.9216\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2909 - accuracy: 0.9184 - val_loss: 0.2800 - val_accuracy: 0.9230\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2849 - accuracy: 0.9200 - val_loss: 0.2748 - val_accuracy: 0.9246\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2794 - accuracy: 0.9219 - val_loss: 0.2695 - val_accuracy: 0.9251\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2742 - accuracy: 0.9235 - val_loss: 0.2652 - val_accuracy: 0.9254\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2694 - accuracy: 0.9244 - val_loss: 0.2609 - val_accuracy: 0.9263\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2648 - accuracy: 0.9257 - val_loss: 0.2568 - val_accuracy: 0.9282\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2604 - accuracy: 0.9271 - val_loss: 0.2532 - val_accuracy: 0.9293\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2563 - accuracy: 0.9282 - val_loss: 0.2496 - val_accuracy: 0.9293\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2524 - accuracy: 0.9290 - val_loss: 0.2462 - val_accuracy: 0.9304\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2486 - accuracy: 0.9302 - val_loss: 0.2434 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2451 - accuracy: 0.9313 - val_loss: 0.2400 - val_accuracy: 0.9316\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2416 - accuracy: 0.9321 - val_loss: 0.2368 - val_accuracy: 0.9327\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2383 - accuracy: 0.9329 - val_loss: 0.2342 - val_accuracy: 0.9330\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2352 - accuracy: 0.9337 - val_loss: 0.2317 - val_accuracy: 0.9343\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2322 - accuracy: 0.9344 - val_loss: 0.2291 - val_accuracy: 0.9346\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2293 - accuracy: 0.9352 - val_loss: 0.2263 - val_accuracy: 0.9345\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2265 - accuracy: 0.9360 - val_loss: 0.2238 - val_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2237 - accuracy: 0.9366 - val_loss: 0.2215 - val_accuracy: 0.9369\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2211 - accuracy: 0.9375 - val_loss: 0.2195 - val_accuracy: 0.9376\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2186 - accuracy: 0.9378 - val_loss: 0.2172 - val_accuracy: 0.9377\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2161 - accuracy: 0.9387 - val_loss: 0.2152 - val_accuracy: 0.9382\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2138 - accuracy: 0.9391 - val_loss: 0.2128 - val_accuracy: 0.9390\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2115 - accuracy: 0.9400 - val_loss: 0.2110 - val_accuracy: 0.9391\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2092 - accuracy: 0.9405 - val_loss: 0.2087 - val_accuracy: 0.9404\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2071 - accuracy: 0.9409 - val_loss: 0.2071 - val_accuracy: 0.9402\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2049 - accuracy: 0.9419 - val_loss: 0.2055 - val_accuracy: 0.9402\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2028 - accuracy: 0.9424 - val_loss: 0.2036 - val_accuracy: 0.9409\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2009 - accuracy: 0.9431 - val_loss: 0.2020 - val_accuracy: 0.9414\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1990 - accuracy: 0.9436 - val_loss: 0.2000 - val_accuracy: 0.9422\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1971 - accuracy: 0.9439 - val_loss: 0.1982 - val_accuracy: 0.9429\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1952 - accuracy: 0.9448 - val_loss: 0.1969 - val_accuracy: 0.9428\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1935 - accuracy: 0.9454 - val_loss: 0.1955 - val_accuracy: 0.9427\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1917 - accuracy: 0.9454 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1900 - accuracy: 0.9462 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1884 - accuracy: 0.9466 - val_loss: 0.1909 - val_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1867 - accuracy: 0.9472 - val_loss: 0.1897 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1851 - accuracy: 0.9475 - val_loss: 0.1883 - val_accuracy: 0.9451\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1835 - accuracy: 0.9480 - val_loss: 0.1873 - val_accuracy: 0.9452\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1821 - accuracy: 0.9482 - val_loss: 0.1857 - val_accuracy: 0.9456\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1806 - accuracy: 0.9487 - val_loss: 0.1844 - val_accuracy: 0.9460\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1791 - accuracy: 0.9490 - val_loss: 0.1832 - val_accuracy: 0.9473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1777 - accuracy: 0.9496 - val_loss: 0.1821 - val_accuracy: 0.9464\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1763 - accuracy: 0.9500 - val_loss: 0.1807 - val_accuracy: 0.9474\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1749 - accuracy: 0.9503 - val_loss: 0.1795 - val_accuracy: 0.9485\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1736 - accuracy: 0.9509 - val_loss: 0.1786 - val_accuracy: 0.9483\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1723 - accuracy: 0.9510 - val_loss: 0.1771 - val_accuracy: 0.9488\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1710 - accuracy: 0.9515 - val_loss: 0.1767 - val_accuracy: 0.9487\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1698 - accuracy: 0.9520 - val_loss: 0.1753 - val_accuracy: 0.9493\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1685 - accuracy: 0.9525 - val_loss: 0.1744 - val_accuracy: 0.9493\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1673 - accuracy: 0.9527 - val_loss: 0.1732 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1661 - accuracy: 0.9534 - val_loss: 0.1722 - val_accuracy: 0.9504\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1649 - accuracy: 0.9535 - val_loss: 0.1714 - val_accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1637 - accuracy: 0.9536 - val_loss: 0.1701 - val_accuracy: 0.9506\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1626 - accuracy: 0.9542 - val_loss: 0.1695 - val_accuracy: 0.9516\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1616 - accuracy: 0.9544 - val_loss: 0.1683 - val_accuracy: 0.9518\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1604 - accuracy: 0.9549 - val_loss: 0.1674 - val_accuracy: 0.9522\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1594 - accuracy: 0.9549 - val_loss: 0.1667 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1583 - accuracy: 0.9556 - val_loss: 0.1657 - val_accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1573 - accuracy: 0.9555 - val_loss: 0.1646 - val_accuracy: 0.9530\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1562 - accuracy: 0.9560 - val_loss: 0.1637 - val_accuracy: 0.9529\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1552 - accuracy: 0.9561 - val_loss: 0.1631 - val_accuracy: 0.9530\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1542 - accuracy: 0.9567 - val_loss: 0.1626 - val_accuracy: 0.9535\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1533 - accuracy: 0.9568 - val_loss: 0.1615 - val_accuracy: 0.9538\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1523 - accuracy: 0.9572 - val_loss: 0.1606 - val_accuracy: 0.9539\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1514 - accuracy: 0.9573 - val_loss: 0.1599 - val_accuracy: 0.9538\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1505 - accuracy: 0.9577 - val_loss: 0.1593 - val_accuracy: 0.9539\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1495 - accuracy: 0.9581 - val_loss: 0.1585 - val_accuracy: 0.9544\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1486 - accuracy: 0.9585 - val_loss: 0.1574 - val_accuracy: 0.9547\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1477 - accuracy: 0.9585 - val_loss: 0.1569 - val_accuracy: 0.9550\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1469 - accuracy: 0.9584 - val_loss: 0.1564 - val_accuracy: 0.9555\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1459 - accuracy: 0.9588 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1452 - accuracy: 0.9592 - val_loss: 0.1550 - val_accuracy: 0.9559\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1443 - accuracy: 0.9593 - val_loss: 0.1545 - val_accuracy: 0.9560\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1435 - accuracy: 0.9597 - val_loss: 0.1535 - val_accuracy: 0.9561\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1427 - accuracy: 0.9597 - val_loss: 0.1529 - val_accuracy: 0.9564\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1418 - accuracy: 0.9602 - val_loss: 0.1523 - val_accuracy: 0.9561\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1411 - accuracy: 0.9601 - val_loss: 0.1516 - val_accuracy: 0.9564\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1402 - accuracy: 0.9607 - val_loss: 0.1512 - val_accuracy: 0.9568\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1395 - accuracy: 0.9608 - val_loss: 0.1503 - val_accuracy: 0.9567\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1388 - accuracy: 0.9611 - val_loss: 0.1498 - val_accuracy: 0.9572\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1380 - accuracy: 0.9611 - val_loss: 0.1493 - val_accuracy: 0.9573\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1373 - accuracy: 0.9615 - val_loss: 0.1485 - val_accuracy: 0.9576\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1365 - accuracy: 0.9617 - val_loss: 0.1481 - val_accuracy: 0.9576\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1358 - accuracy: 0.9620 - val_loss: 0.1474 - val_accuracy: 0.9582\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1351 - accuracy: 0.9622 - val_loss: 0.1466 - val_accuracy: 0.9584\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1344 - accuracy: 0.9624 - val_loss: 0.1461 - val_accuracy: 0.9578\n",
      "Total compute time to train model_4b was: 101.33 seconds\n",
      "Training Accuracy: 0.9624\n",
      "Test Accuracy: 0.9578\n",
      "Training Loss: 0.1344\n",
      "Test Loss: 0.1461\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "#model_4b uses tanh as the activation function\n",
    "model_4b = Sequential()\n",
    "model_4b.add(Dense(units=32, activation='tanh', input_shape=(784,))) \n",
    "model_4b.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_4b.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_4b_history = model_4b.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_4b was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_4b_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_4b_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_4b_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_4b_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3119 - accuracy: 0.6456 - val_loss: 0.7399 - val_accuracy: 0.8275\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.6163 - accuracy: 0.8434 - val_loss: 0.4981 - val_accuracy: 0.8701\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4738 - accuracy: 0.8721 - val_loss: 0.4155 - val_accuracy: 0.8856\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4139 - accuracy: 0.8847 - val_loss: 0.3743 - val_accuracy: 0.8948\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3797 - accuracy: 0.8928 - val_loss: 0.3484 - val_accuracy: 0.9014\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3565 - accuracy: 0.8989 - val_loss: 0.3306 - val_accuracy: 0.9053\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3396 - accuracy: 0.9033 - val_loss: 0.3169 - val_accuracy: 0.9095\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3260 - accuracy: 0.9069 - val_loss: 0.3055 - val_accuracy: 0.9128\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3148 - accuracy: 0.9104 - val_loss: 0.2968 - val_accuracy: 0.9162\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3051 - accuracy: 0.9128 - val_loss: 0.2882 - val_accuracy: 0.9170\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2967 - accuracy: 0.9154 - val_loss: 0.2818 - val_accuracy: 0.9183\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2891 - accuracy: 0.9176 - val_loss: 0.2753 - val_accuracy: 0.9205\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2822 - accuracy: 0.9192 - val_loss: 0.2701 - val_accuracy: 0.9237\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2759 - accuracy: 0.9215 - val_loss: 0.2643 - val_accuracy: 0.9248\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2702 - accuracy: 0.9234 - val_loss: 0.2589 - val_accuracy: 0.9255\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2646 - accuracy: 0.9252 - val_loss: 0.2548 - val_accuracy: 0.9273\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2595 - accuracy: 0.9263 - val_loss: 0.2501 - val_accuracy: 0.9277\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2547 - accuracy: 0.9280 - val_loss: 0.2462 - val_accuracy: 0.9294\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2501 - accuracy: 0.9295 - val_loss: 0.2425 - val_accuracy: 0.9302\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2457 - accuracy: 0.9309 - val_loss: 0.2391 - val_accuracy: 0.9309\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2415 - accuracy: 0.9317 - val_loss: 0.2357 - val_accuracy: 0.9329\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2375 - accuracy: 0.9337 - val_loss: 0.2317 - val_accuracy: 0.9344\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2338 - accuracy: 0.9348 - val_loss: 0.2277 - val_accuracy: 0.9348\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2303 - accuracy: 0.9356 - val_loss: 0.2255 - val_accuracy: 0.9365\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2268 - accuracy: 0.9367 - val_loss: 0.2231 - val_accuracy: 0.9373\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2238 - accuracy: 0.9376 - val_loss: 0.2193 - val_accuracy: 0.9386\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2205 - accuracy: 0.9383 - val_loss: 0.2169 - val_accuracy: 0.9393\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2176 - accuracy: 0.9393 - val_loss: 0.2138 - val_accuracy: 0.9394\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2147 - accuracy: 0.9401 - val_loss: 0.2112 - val_accuracy: 0.9395\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2120 - accuracy: 0.9407 - val_loss: 0.2095 - val_accuracy: 0.9415\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2093 - accuracy: 0.9414 - val_loss: 0.2071 - val_accuracy: 0.9411\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2066 - accuracy: 0.9426 - val_loss: 0.2050 - val_accuracy: 0.9408\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2042 - accuracy: 0.9431 - val_loss: 0.2028 - val_accuracy: 0.9420\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2017 - accuracy: 0.9443 - val_loss: 0.2005 - val_accuracy: 0.9432\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1994 - accuracy: 0.9445 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1971 - accuracy: 0.9451 - val_loss: 0.1962 - val_accuracy: 0.9443\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1949 - accuracy: 0.9460 - val_loss: 0.1940 - val_accuracy: 0.9447\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1927 - accuracy: 0.9462 - val_loss: 0.1931 - val_accuracy: 0.9449\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1906 - accuracy: 0.9469 - val_loss: 0.1913 - val_accuracy: 0.9458\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1886 - accuracy: 0.9474 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1866 - accuracy: 0.9484 - val_loss: 0.1884 - val_accuracy: 0.9456\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1847 - accuracy: 0.9487 - val_loss: 0.1862 - val_accuracy: 0.9473\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1829 - accuracy: 0.9491 - val_loss: 0.1844 - val_accuracy: 0.9469\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1810 - accuracy: 0.9495 - val_loss: 0.1823 - val_accuracy: 0.9471\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1793 - accuracy: 0.9502 - val_loss: 0.1810 - val_accuracy: 0.9477\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1775 - accuracy: 0.9508 - val_loss: 0.1800 - val_accuracy: 0.9482\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1758 - accuracy: 0.9511 - val_loss: 0.1786 - val_accuracy: 0.9485\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1742 - accuracy: 0.9513 - val_loss: 0.1766 - val_accuracy: 0.9488\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1725 - accuracy: 0.9518 - val_loss: 0.1759 - val_accuracy: 0.9484\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1711 - accuracy: 0.9524 - val_loss: 0.1742 - val_accuracy: 0.9490\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1695 - accuracy: 0.9528 - val_loss: 0.1733 - val_accuracy: 0.9502\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1680 - accuracy: 0.9532 - val_loss: 0.1715 - val_accuracy: 0.9496\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1665 - accuracy: 0.9540 - val_loss: 0.1704 - val_accuracy: 0.9498\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1651 - accuracy: 0.9537 - val_loss: 0.1694 - val_accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1635 - accuracy: 0.9542 - val_loss: 0.1680 - val_accuracy: 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1622 - accuracy: 0.9549 - val_loss: 0.1672 - val_accuracy: 0.9508\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1609 - accuracy: 0.9554 - val_loss: 0.1661 - val_accuracy: 0.9511\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1594 - accuracy: 0.9558 - val_loss: 0.1652 - val_accuracy: 0.9512\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1581 - accuracy: 0.9562 - val_loss: 0.1646 - val_accuracy: 0.9519\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1568 - accuracy: 0.9563 - val_loss: 0.1630 - val_accuracy: 0.9521\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1556 - accuracy: 0.9568 - val_loss: 0.1612 - val_accuracy: 0.9519\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1542 - accuracy: 0.9571 - val_loss: 0.1611 - val_accuracy: 0.9524\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1531 - accuracy: 0.9573 - val_loss: 0.1595 - val_accuracy: 0.9525\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1519 - accuracy: 0.9576 - val_loss: 0.1586 - val_accuracy: 0.9533\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1507 - accuracy: 0.9581 - val_loss: 0.1578 - val_accuracy: 0.9532\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1495 - accuracy: 0.9582 - val_loss: 0.1567 - val_accuracy: 0.9530\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1484 - accuracy: 0.9586 - val_loss: 0.1560 - val_accuracy: 0.9535\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1472 - accuracy: 0.9588 - val_loss: 0.1548 - val_accuracy: 0.9546\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1462 - accuracy: 0.9589 - val_loss: 0.1541 - val_accuracy: 0.9540\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1450 - accuracy: 0.9595 - val_loss: 0.1544 - val_accuracy: 0.9542\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1441 - accuracy: 0.9596 - val_loss: 0.1530 - val_accuracy: 0.9548\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1430 - accuracy: 0.9603 - val_loss: 0.1517 - val_accuracy: 0.9553\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1420 - accuracy: 0.9603 - val_loss: 0.1508 - val_accuracy: 0.9553\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1409 - accuracy: 0.9606 - val_loss: 0.1500 - val_accuracy: 0.9556\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1399 - accuracy: 0.9609 - val_loss: 0.1497 - val_accuracy: 0.9553\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1389 - accuracy: 0.9611 - val_loss: 0.1495 - val_accuracy: 0.9552\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1380 - accuracy: 0.9612 - val_loss: 0.1479 - val_accuracy: 0.9564\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1372 - accuracy: 0.9618 - val_loss: 0.1468 - val_accuracy: 0.9562\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1361 - accuracy: 0.9617 - val_loss: 0.1464 - val_accuracy: 0.9563\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1353 - accuracy: 0.9622 - val_loss: 0.1451 - val_accuracy: 0.9573\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1343 - accuracy: 0.9625 - val_loss: 0.1456 - val_accuracy: 0.9565\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1334 - accuracy: 0.9630 - val_loss: 0.1447 - val_accuracy: 0.9569\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1326 - accuracy: 0.9631 - val_loss: 0.1438 - val_accuracy: 0.9574\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1316 - accuracy: 0.9635 - val_loss: 0.1428 - val_accuracy: 0.9577\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1308 - accuracy: 0.9637 - val_loss: 0.1427 - val_accuracy: 0.9583\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1300 - accuracy: 0.9639 - val_loss: 0.1418 - val_accuracy: 0.9576\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1292 - accuracy: 0.9640 - val_loss: 0.1413 - val_accuracy: 0.9578\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1282 - accuracy: 0.9643 - val_loss: 0.1407 - val_accuracy: 0.9577\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1275 - accuracy: 0.9644 - val_loss: 0.1403 - val_accuracy: 0.9587\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1267 - accuracy: 0.9651 - val_loss: 0.1392 - val_accuracy: 0.9585\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1260 - accuracy: 0.9652 - val_loss: 0.1389 - val_accuracy: 0.9586\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1252 - accuracy: 0.9653 - val_loss: 0.1383 - val_accuracy: 0.9582\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1245 - accuracy: 0.9656 - val_loss: 0.1375 - val_accuracy: 0.9586\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1237 - accuracy: 0.9657 - val_loss: 0.1375 - val_accuracy: 0.9586\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1230 - accuracy: 0.9658 - val_loss: 0.1371 - val_accuracy: 0.9582\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1222 - accuracy: 0.9664 - val_loss: 0.1371 - val_accuracy: 0.9588\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1215 - accuracy: 0.9663 - val_loss: 0.1362 - val_accuracy: 0.9585\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1209 - accuracy: 0.9664 - val_loss: 0.1348 - val_accuracy: 0.9594\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1202 - accuracy: 0.9662 - val_loss: 0.1347 - val_accuracy: 0.9594\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1195 - accuracy: 0.9668 - val_loss: 0.1343 - val_accuracy: 0.9594\n",
      "Total compute time to train model_4c was: 98.62 seconds\n",
      "Training Accuracy: 0.9668\n",
      "Test Accuracy: 0.9594\n",
      "Training Loss: 0.1195\n",
      "Test Loss: 0.1343\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "#model_4c uses relu as the activation function\n",
    "model_4c = Sequential()\n",
    "model_4c.add(Dense(units=32, activation='relu', input_shape=(784,))) \n",
    "model_4c.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_4c.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_4c_history = model_4c.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_4c was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_4c_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_4c_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_4c_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_4c_history.history['val_loss'][-1]:.4f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Plotting tanh and relu activations overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_4b_history_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d8843b4566ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_4b_history_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Test Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_4b tanh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_4c_history_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Test Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_4c relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Number of Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.091\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vertical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_4b_history_df' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(22,6))\n",
    "model_4b_history_df[['Training Accuracy','Test Accuracy']].plot(ax=ax[0], title='model_4b tanh',xlim=[15,100], ylim=[0.92,0.97])\n",
    "model_4c_history_df[['Training Accuracy','Test Accuracy']].plot(ax=ax[1], title='model_4c relu',xlim=[15,100], ylim=[0.92,0.97])\n",
    "fig.text(0.5, 0.04, 'Number of Epochs')\n",
    "fig.text(0.091, 0.5, 'Accuracy', va='center', rotation='vertical')\n",
    "fig.suptitle('Tanh and RELU Activations Overfitting')\n",
    "plt.savefig('tanh_and_relu_overfitting.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Investigating Effect of Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3536 - accuracy: 0.6452 - val_loss: 0.7624 - val_accuracy: 0.8281\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6290 - accuracy: 0.8501 - val_loss: 0.5114 - val_accuracy: 0.8791\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4817 - accuracy: 0.8760 - val_loss: 0.4250 - val_accuracy: 0.8907\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4204 - accuracy: 0.8869 - val_loss: 0.3822 - val_accuracy: 0.8988\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3864 - accuracy: 0.8938 - val_loss: 0.3563 - val_accuracy: 0.9046\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.89 - 1s 17us/step - loss: 0.3640 - accuracy: 0.8989 - val_loss: 0.3390 - val_accuracy: 0.9071\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3476 - accuracy: 0.9032 - val_loss: 0.3250 - val_accuracy: 0.9115\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3352 - accuracy: 0.9063 - val_loss: 0.3145 - val_accuracy: 0.9140\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3247 - accuracy: 0.9087 - val_loss: 0.3062 - val_accuracy: 0.9159\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3159 - accuracy: 0.9114 - val_loss: 0.2985 - val_accuracy: 0.9173\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3081 - accuracy: 0.9130 - val_loss: 0.2930 - val_accuracy: 0.9190\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3013 - accuracy: 0.9153 - val_loss: 0.2872 - val_accuracy: 0.9210\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2950 - accuracy: 0.9164 - val_loss: 0.2809 - val_accuracy: 0.9224\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2894 - accuracy: 0.9183 - val_loss: 0.2772 - val_accuracy: 0.9234\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2839 - accuracy: 0.9200 - val_loss: 0.2724 - val_accuracy: 0.9250\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2790 - accuracy: 0.9220 - val_loss: 0.2676 - val_accuracy: 0.9259\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2741 - accuracy: 0.9230 - val_loss: 0.2641 - val_accuracy: 0.9252\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2700 - accuracy: 0.9243 - val_loss: 0.2604 - val_accuracy: 0.9281\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2657 - accuracy: 0.9257 - val_loss: 0.2563 - val_accuracy: 0.9280\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2619 - accuracy: 0.9270 - val_loss: 0.2527 - val_accuracy: 0.9304\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2580 - accuracy: 0.9278 - val_loss: 0.2502 - val_accuracy: 0.9300\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.2544 - accuracy: 0.9295 - val_loss: 0.2471 - val_accuracy: 0.9307\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2509 - accuracy: 0.9301 - val_loss: 0.2435 - val_accuracy: 0.9311\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2474 - accuracy: 0.9315 - val_loss: 0.2415 - val_accuracy: 0.9326\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2444 - accuracy: 0.9319 - val_loss: 0.2384 - val_accuracy: 0.9332\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2412 - accuracy: 0.9331 - val_loss: 0.2351 - val_accuracy: 0.9337\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2381 - accuracy: 0.9339 - val_loss: 0.2328 - val_accuracy: 0.9340\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2352 - accuracy: 0.9349 - val_loss: 0.2309 - val_accuracy: 0.9339\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2324 - accuracy: 0.9355 - val_loss: 0.2283 - val_accuracy: 0.9355\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2297 - accuracy: 0.9362 - val_loss: 0.2252 - val_accuracy: 0.9351\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2270 - accuracy: 0.9370 - val_loss: 0.2224 - val_accuracy: 0.9368\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2245 - accuracy: 0.9376 - val_loss: 0.2202 - val_accuracy: 0.9379\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2219 - accuracy: 0.9383 - val_loss: 0.2189 - val_accuracy: 0.9382\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2193 - accuracy: 0.9392 - val_loss: 0.2158 - val_accuracy: 0.9380\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2170 - accuracy: 0.9400 - val_loss: 0.2139 - val_accuracy: 0.9387\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2146 - accuracy: 0.9407 - val_loss: 0.2130 - val_accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2124 - accuracy: 0.9413 - val_loss: 0.2102 - val_accuracy: 0.9408\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2101 - accuracy: 0.9415 - val_loss: 0.2086 - val_accuracy: 0.9406\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2080 - accuracy: 0.9423 - val_loss: 0.2055 - val_accuracy: 0.9420\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2059 - accuracy: 0.9428 - val_loss: 0.2049 - val_accuracy: 0.9412\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2037 - accuracy: 0.9432 - val_loss: 0.2023 - val_accuracy: 0.9438\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2016 - accuracy: 0.9441 - val_loss: 0.2008 - val_accuracy: 0.9430\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1997 - accuracy: 0.9449 - val_loss: 0.1997 - val_accuracy: 0.9421\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1978 - accuracy: 0.9454 - val_loss: 0.1970 - val_accuracy: 0.9425\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1958 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9433\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1939 - accuracy: 0.9461 - val_loss: 0.1944 - val_accuracy: 0.9432\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1922 - accuracy: 0.9470 - val_loss: 0.1931 - val_accuracy: 0.9447\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1903 - accuracy: 0.9474 - val_loss: 0.1912 - val_accuracy: 0.9448\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1885 - accuracy: 0.9478 - val_loss: 0.1894 - val_accuracy: 0.9463\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1869 - accuracy: 0.9479 - val_loss: 0.1886 - val_accuracy: 0.9467\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1852 - accuracy: 0.9485 - val_loss: 0.1868 - val_accuracy: 0.9463\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1835 - accuracy: 0.9492 - val_loss: 0.1849 - val_accuracy: 0.9472\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1820 - accuracy: 0.9492 - val_loss: 0.1840 - val_accuracy: 0.9469\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1803 - accuracy: 0.9500 - val_loss: 0.1827 - val_accuracy: 0.9469\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1788 - accuracy: 0.9502 - val_loss: 0.1814 - val_accuracy: 0.9483\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1774 - accuracy: 0.9510 - val_loss: 0.1805 - val_accuracy: 0.9481\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1759 - accuracy: 0.9511 - val_loss: 0.1793 - val_accuracy: 0.9476\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1745 - accuracy: 0.9514 - val_loss: 0.1775 - val_accuracy: 0.9484\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1730 - accuracy: 0.9523 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1717 - accuracy: 0.9519 - val_loss: 0.1762 - val_accuracy: 0.9497\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1704 - accuracy: 0.9526 - val_loss: 0.1747 - val_accuracy: 0.9493\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1690 - accuracy: 0.9530 - val_loss: 0.1739 - val_accuracy: 0.9496\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1677 - accuracy: 0.9530 - val_loss: 0.1727 - val_accuracy: 0.9508\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1663 - accuracy: 0.9536 - val_loss: 0.1714 - val_accuracy: 0.9511\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1651 - accuracy: 0.9541 - val_loss: 0.1711 - val_accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1638 - accuracy: 0.9544 - val_loss: 0.1700 - val_accuracy: 0.9506\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1626 - accuracy: 0.9545 - val_loss: 0.1689 - val_accuracy: 0.9522\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1613 - accuracy: 0.9553 - val_loss: 0.1679 - val_accuracy: 0.9518\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1601 - accuracy: 0.9555 - val_loss: 0.1673 - val_accuracy: 0.9508\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1589 - accuracy: 0.9559 - val_loss: 0.1656 - val_accuracy: 0.9527\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1578 - accuracy: 0.9561 - val_loss: 0.1650 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1567 - accuracy: 0.9564 - val_loss: 0.1647 - val_accuracy: 0.9523\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1556 - accuracy: 0.9566 - val_loss: 0.1629 - val_accuracy: 0.9531\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1545 - accuracy: 0.9573 - val_loss: 0.1621 - val_accuracy: 0.9536\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1534 - accuracy: 0.9571 - val_loss: 0.1613 - val_accuracy: 0.9535\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1523 - accuracy: 0.9578 - val_loss: 0.1608 - val_accuracy: 0.9538\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1513 - accuracy: 0.9579 - val_loss: 0.1600 - val_accuracy: 0.9541\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1502 - accuracy: 0.9582 - val_loss: 0.1593 - val_accuracy: 0.9543\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1493 - accuracy: 0.9584 - val_loss: 0.1584 - val_accuracy: 0.9548\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1482 - accuracy: 0.9590 - val_loss: 0.1577 - val_accuracy: 0.9548\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1472 - accuracy: 0.9589 - val_loss: 0.1575 - val_accuracy: 0.9548\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1463 - accuracy: 0.9589 - val_loss: 0.1563 - val_accuracy: 0.9547\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1454 - accuracy: 0.9593 - val_loss: 0.1554 - val_accuracy: 0.9555\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1444 - accuracy: 0.9597 - val_loss: 0.1550 - val_accuracy: 0.9557\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1435 - accuracy: 0.9601 - val_loss: 0.1549 - val_accuracy: 0.9557\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1426 - accuracy: 0.9604 - val_loss: 0.1538 - val_accuracy: 0.9560\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1417 - accuracy: 0.9603 - val_loss: 0.1528 - val_accuracy: 0.9564\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1408 - accuracy: 0.9607 - val_loss: 0.1520 - val_accuracy: 0.9560\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1400 - accuracy: 0.9608 - val_loss: 0.1513 - val_accuracy: 0.9564\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1390 - accuracy: 0.9608 - val_loss: 0.1510 - val_accuracy: 0.9571\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1383 - accuracy: 0.9612 - val_loss: 0.1499 - val_accuracy: 0.9567\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1374 - accuracy: 0.9613 - val_loss: 0.1501 - val_accuracy: 0.9573\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1366 - accuracy: 0.9616 - val_loss: 0.1492 - val_accuracy: 0.9566\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1358 - accuracy: 0.9620 - val_loss: 0.1488 - val_accuracy: 0.9573\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1351 - accuracy: 0.9623 - val_loss: 0.1480 - val_accuracy: 0.9569\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1342 - accuracy: 0.9623 - val_loss: 0.1478 - val_accuracy: 0.9565\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1334 - accuracy: 0.9626 - val_loss: 0.1469 - val_accuracy: 0.9579\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1326 - accuracy: 0.9627 - val_loss: 0.1461 - val_accuracy: 0.9569\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1319 - accuracy: 0.9631 - val_loss: 0.1460 - val_accuracy: 0.9576\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1312 - accuracy: 0.9635 - val_loss: 0.1457 - val_accuracy: 0.9581\n",
      "Total compute time to train model_5a was: 105.19 seconds\n",
      "Training Accuracy: 0.9635\n",
      "Test Accuracy: 0.9581\n",
      "Training Loss: 0.1312\n",
      "Test Loss: 0.1457\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "\n",
    "#model_5a uses one hidden layer\n",
    "model_5a = Sequential()\n",
    "model_5a.add(Dense(units=32, activation='relu', input_shape=(784,))) \n",
    "model_5a.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_5a.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_5a_history = model_5a.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_5a was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_5a_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_5a_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_5a_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_5a_history.history['val_loss'][-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.5734 - accuracy: 0.5475 - val_loss: 0.8789 - val_accuracy: 0.7749\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6904 - accuracy: 0.8080 - val_loss: 0.5372 - val_accuracy: 0.8444\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4991 - accuracy: 0.8599 - val_loss: 0.4261 - val_accuracy: 0.8811\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4165 - accuracy: 0.8838 - val_loss: 0.3692 - val_accuracy: 0.8955\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3711 - accuracy: 0.8962 - val_loss: 0.3351 - val_accuracy: 0.9051\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3420 - accuracy: 0.9036 - val_loss: 0.3135 - val_accuracy: 0.9108\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3211 - accuracy: 0.9100 - val_loss: 0.2982 - val_accuracy: 0.9142\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3052 - accuracy: 0.9142 - val_loss: 0.2872 - val_accuracy: 0.9204\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2921 - accuracy: 0.9184 - val_loss: 0.2741 - val_accuracy: 0.9226\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2807 - accuracy: 0.9210 - val_loss: 0.2667 - val_accuracy: 0.9245\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2709 - accuracy: 0.9240 - val_loss: 0.2604 - val_accuracy: 0.9273\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2622 - accuracy: 0.9260 - val_loss: 0.2509 - val_accuracy: 0.9303\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2545 - accuracy: 0.9288 - val_loss: 0.2431 - val_accuracy: 0.9329\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2474 - accuracy: 0.9300 - val_loss: 0.2396 - val_accuracy: 0.9341\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2410 - accuracy: 0.9319 - val_loss: 0.2336 - val_accuracy: 0.9334\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2351 - accuracy: 0.9330 - val_loss: 0.2259 - val_accuracy: 0.9360\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2294 - accuracy: 0.9349 - val_loss: 0.2219 - val_accuracy: 0.9362\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2241 - accuracy: 0.9363 - val_loss: 0.2167 - val_accuracy: 0.9391\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2192 - accuracy: 0.9376 - val_loss: 0.2134 - val_accuracy: 0.9390\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2144 - accuracy: 0.9388 - val_loss: 0.2091 - val_accuracy: 0.9409\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2098 - accuracy: 0.9405 - val_loss: 0.2066 - val_accuracy: 0.9400\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2055 - accuracy: 0.9414 - val_loss: 0.2025 - val_accuracy: 0.9409\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2016 - accuracy: 0.9428 - val_loss: 0.1999 - val_accuracy: 0.9437\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1976 - accuracy: 0.9438 - val_loss: 0.1946 - val_accuracy: 0.9439\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1938 - accuracy: 0.9449 - val_loss: 0.1949 - val_accuracy: 0.9443\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1900 - accuracy: 0.9459 - val_loss: 0.1894 - val_accuracy: 0.9454\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1867 - accuracy: 0.9463 - val_loss: 0.1881 - val_accuracy: 0.9467\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1832 - accuracy: 0.9474 - val_loss: 0.1836 - val_accuracy: 0.9471\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1799 - accuracy: 0.9484 - val_loss: 0.1823 - val_accuracy: 0.9480\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1769 - accuracy: 0.9493 - val_loss: 0.1786 - val_accuracy: 0.9481\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1736 - accuracy: 0.9503 - val_loss: 0.1776 - val_accuracy: 0.9493\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1708 - accuracy: 0.9514 - val_loss: 0.1735 - val_accuracy: 0.9490\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1679 - accuracy: 0.9523 - val_loss: 0.1728 - val_accuracy: 0.9504\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1653 - accuracy: 0.9530 - val_loss: 0.1681 - val_accuracy: 0.9519\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1624 - accuracy: 0.9535 - val_loss: 0.1670 - val_accuracy: 0.9513\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1599 - accuracy: 0.9545 - val_loss: 0.1649 - val_accuracy: 0.9529\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1572 - accuracy: 0.9556 - val_loss: 0.1627 - val_accuracy: 0.9534\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1548 - accuracy: 0.9559 - val_loss: 0.1600 - val_accuracy: 0.9542\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1524 - accuracy: 0.9561 - val_loss: 0.1588 - val_accuracy: 0.9539 0s - loss: 0.1\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1500 - accuracy: 0.9570 - val_loss: 0.1574 - val_accuracy: 0.9542\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1477 - accuracy: 0.9580 - val_loss: 0.1558 - val_accuracy: 0.9547\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1457 - accuracy: 0.9584 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1433 - accuracy: 0.9590 - val_loss: 0.1526 - val_accuracy: 0.9562\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1415 - accuracy: 0.9597 - val_loss: 0.1513 - val_accuracy: 0.9556\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1394 - accuracy: 0.9601 - val_loss: 0.1487 - val_accuracy: 0.9559\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1374 - accuracy: 0.9606 - val_loss: 0.1481 - val_accuracy: 0.9571\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1356 - accuracy: 0.9612 - val_loss: 0.1467 - val_accuracy: 0.9575\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1337 - accuracy: 0.9615 - val_loss: 0.1446 - val_accuracy: 0.9568\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1318 - accuracy: 0.9624 - val_loss: 0.1438 - val_accuracy: 0.9577\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1298 - accuracy: 0.9628 - val_loss: 0.1419 - val_accuracy: 0.9586\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1284 - accuracy: 0.9628 - val_loss: 0.1406 - val_accuracy: 0.9581\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1267 - accuracy: 0.9638 - val_loss: 0.1402 - val_accuracy: 0.9580\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1250 - accuracy: 0.9639 - val_loss: 0.1390 - val_accuracy: 0.9578\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1235 - accuracy: 0.9646 - val_loss: 0.1380 - val_accuracy: 0.9586\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1219 - accuracy: 0.9648 - val_loss: 0.1372 - val_accuracy: 0.9589\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1204 - accuracy: 0.9653 - val_loss: 0.1347 - val_accuracy: 0.9602\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1190 - accuracy: 0.9656 - val_loss: 0.1358 - val_accuracy: 0.9595\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1176 - accuracy: 0.9660 - val_loss: 0.1328 - val_accuracy: 0.9602\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1162 - accuracy: 0.9665 - val_loss: 0.1338 - val_accuracy: 0.9597\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1149 - accuracy: 0.9671 - val_loss: 0.1313 - val_accuracy: 0.9613\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1135 - accuracy: 0.9669 - val_loss: 0.1306 - val_accuracy: 0.9608\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1122 - accuracy: 0.9677 - val_loss: 0.1303 - val_accuracy: 0.9622\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1108 - accuracy: 0.9680 - val_loss: 0.1287 - val_accuracy: 0.9618\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1096 - accuracy: 0.9685 - val_loss: 0.1272 - val_accuracy: 0.9623\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1085 - accuracy: 0.9684 - val_loss: 0.1276 - val_accuracy: 0.9619\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1072 - accuracy: 0.9689 - val_loss: 0.1268 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1061 - accuracy: 0.9694 - val_loss: 0.1253 - val_accuracy: 0.9632\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1049 - accuracy: 0.9700 - val_loss: 0.1248 - val_accuracy: 0.9625\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1036 - accuracy: 0.9702 - val_loss: 0.1249 - val_accuracy: 0.9622\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1026 - accuracy: 0.9704 - val_loss: 0.1225 - val_accuracy: 0.9634\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1015 - accuracy: 0.9709 - val_loss: 0.1229 - val_accuracy: 0.9639\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1006 - accuracy: 0.9710 - val_loss: 0.1247 - val_accuracy: 0.9623\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0996 - accuracy: 0.9713 - val_loss: 0.1224 - val_accuracy: 0.9631\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0985 - accuracy: 0.9718 - val_loss: 0.1212 - val_accuracy: 0.9635\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0976 - accuracy: 0.9716 - val_loss: 0.1204 - val_accuracy: 0.9638\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0966 - accuracy: 0.9722 - val_loss: 0.1199 - val_accuracy: 0.9645\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0956 - accuracy: 0.9725 - val_loss: 0.1198 - val_accuracy: 0.9638\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0946 - accuracy: 0.9728 - val_loss: 0.1184 - val_accuracy: 0.9645\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0939 - accuracy: 0.9732 - val_loss: 0.1185 - val_accuracy: 0.9640\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0927 - accuracy: 0.9735 - val_loss: 0.1177 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0919 - accuracy: 0.9735 - val_loss: 0.1159 - val_accuracy: 0.9640\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0911 - accuracy: 0.9738 - val_loss: 0.1165 - val_accuracy: 0.9652\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0903 - accuracy: 0.9743 - val_loss: 0.1167 - val_accuracy: 0.9640\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0894 - accuracy: 0.9746 - val_loss: 0.1157 - val_accuracy: 0.9641\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0885 - accuracy: 0.9745 - val_loss: 0.1149 - val_accuracy: 0.9650\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0878 - accuracy: 0.9750 - val_loss: 0.1150 - val_accuracy: 0.9657\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0871 - accuracy: 0.9750 - val_loss: 0.1149 - val_accuracy: 0.9644\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0861 - accuracy: 0.9754 - val_loss: 0.1133 - val_accuracy: 0.9660\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0854 - accuracy: 0.9754 - val_loss: 0.1131 - val_accuracy: 0.9651\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0847 - accuracy: 0.9761 - val_loss: 0.1128 - val_accuracy: 0.9658\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0838 - accuracy: 0.9758 - val_loss: 0.1136 - val_accuracy: 0.9656\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0833 - accuracy: 0.9763 - val_loss: 0.1136 - val_accuracy: 0.9662\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0825 - accuracy: 0.9767 - val_loss: 0.1140 - val_accuracy: 0.9651\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0820 - accuracy: 0.9767 - val_loss: 0.1120 - val_accuracy: 0.9660\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0813 - accuracy: 0.9768 - val_loss: 0.1117 - val_accuracy: 0.9655\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0804 - accuracy: 0.9771 - val_loss: 0.1115 - val_accuracy: 0.9656\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0798 - accuracy: 0.9775 - val_loss: 0.1110 - val_accuracy: 0.9652\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0791 - accuracy: 0.9775 - val_loss: 0.1119 - val_accuracy: 0.9666\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0783 - accuracy: 0.9776 - val_loss: 0.1119 - val_accuracy: 0.9663\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 0.1107 - val_accuracy: 0.9666\n",
      "Total compute time to train model_5b was: 103.73 seconds\n",
      "Training Accuracy: 0.9775\n",
      "Test Accuracy: 0.9666\n",
      "Training Loss: 0.0779\n",
      "Test Loss: 0.1107\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "\n",
    "#model_5b uses two hidden layer\n",
    "model_5b = Sequential()\n",
    "model_5b.add(Dense(units=32, activation='relu', input_shape=(784,)))\n",
    "model_5b.add(Dense(units=32, activation='relu')) \n",
    "model_5b.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_5b.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_5b_history = model_5b.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_5b was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_5b_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_5b_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_5b_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_5b_history.history['val_loss'][-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.8080 - accuracy: 0.4221 - val_loss: 1.0233 - val_accuracy: 0.7446\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6855 - accuracy: 0.8150 - val_loss: 0.4914 - val_accuracy: 0.8646\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4484 - accuracy: 0.8712 - val_loss: 0.3888 - val_accuracy: 0.8913\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3807 - accuracy: 0.8905 - val_loss: 0.3498 - val_accuracy: 0.8997\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3437 - accuracy: 0.9005 - val_loss: 0.3158 - val_accuracy: 0.9087\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3180 - accuracy: 0.9072 - val_loss: 0.2930 - val_accuracy: 0.9147\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2967 - accuracy: 0.9135 - val_loss: 0.2765 - val_accuracy: 0.9172\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2786 - accuracy: 0.9188 - val_loss: 0.2702 - val_accuracy: 0.9203\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2636 - accuracy: 0.9231 - val_loss: 0.2517 - val_accuracy: 0.9268\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2501 - accuracy: 0.9269 - val_loss: 0.2348 - val_accuracy: 0.9307\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2387 - accuracy: 0.9298 - val_loss: 0.2279 - val_accuracy: 0.9322\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2283 - accuracy: 0.9336 - val_loss: 0.2172 - val_accuracy: 0.9366\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2192 - accuracy: 0.9365 - val_loss: 0.2099 - val_accuracy: 0.9384\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2106 - accuracy: 0.9383 - val_loss: 0.2034 - val_accuracy: 0.9431\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2036 - accuracy: 0.9402 - val_loss: 0.1957 - val_accuracy: 0.9437\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1970 - accuracy: 0.9422 - val_loss: 0.1907 - val_accuracy: 0.9449\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1908 - accuracy: 0.9445 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1850 - accuracy: 0.9465 - val_loss: 0.1832 - val_accuracy: 0.9468\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1802 - accuracy: 0.9471 - val_loss: 0.1814 - val_accuracy: 0.9469\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1752 - accuracy: 0.9485 - val_loss: 0.1770 - val_accuracy: 0.9481\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1706 - accuracy: 0.9497 - val_loss: 0.1742 - val_accuracy: 0.9490\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1668 - accuracy: 0.9507 - val_loss: 0.1683 - val_accuracy: 0.9509\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1630 - accuracy: 0.9519 - val_loss: 0.1654 - val_accuracy: 0.9516\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1594 - accuracy: 0.9535 - val_loss: 0.1632 - val_accuracy: 0.9502\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1559 - accuracy: 0.9540 - val_loss: 0.1586 - val_accuracy: 0.9533\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1520 - accuracy: 0.9547 - val_loss: 0.1595 - val_accuracy: 0.9532\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1493 - accuracy: 0.9558 - val_loss: 0.1585 - val_accuracy: 0.9534\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1462 - accuracy: 0.9565 - val_loss: 0.1548 - val_accuracy: 0.9544\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1431 - accuracy: 0.9578 - val_loss: 0.1507 - val_accuracy: 0.9544\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1404 - accuracy: 0.9584 - val_loss: 0.1488 - val_accuracy: 0.9560\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1378 - accuracy: 0.9591 - val_loss: 0.1475 - val_accuracy: 0.9574\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1351 - accuracy: 0.9601 - val_loss: 0.1449 - val_accuracy: 0.9574\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1325 - accuracy: 0.9607 - val_loss: 0.1443 - val_accuracy: 0.9577\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1303 - accuracy: 0.9615 - val_loss: 0.1426 - val_accuracy: 0.9590\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1275 - accuracy: 0.9621 - val_loss: 0.1419 - val_accuracy: 0.9576\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1255 - accuracy: 0.9627 - val_loss: 0.1435 - val_accuracy: 0.9578\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1236 - accuracy: 0.9630 - val_loss: 0.1374 - val_accuracy: 0.9588\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1211 - accuracy: 0.9642 - val_loss: 0.1374 - val_accuracy: 0.9588\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1193 - accuracy: 0.9647 - val_loss: 0.1375 - val_accuracy: 0.9605\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1170 - accuracy: 0.9651 - val_loss: 0.1352 - val_accuracy: 0.9587\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1155 - accuracy: 0.9660 - val_loss: 0.1327 - val_accuracy: 0.9601\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1136 - accuracy: 0.9661 - val_loss: 0.1323 - val_accuracy: 0.9605\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1116 - accuracy: 0.9671 - val_loss: 0.1310 - val_accuracy: 0.9601\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1096 - accuracy: 0.9678 - val_loss: 0.1328 - val_accuracy: 0.9612\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1081 - accuracy: 0.9682 - val_loss: 0.1276 - val_accuracy: 0.9628\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1059 - accuracy: 0.9692 - val_loss: 0.1297 - val_accuracy: 0.9619\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1046 - accuracy: 0.9684 - val_loss: 0.1292 - val_accuracy: 0.9620\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1028 - accuracy: 0.9696 - val_loss: 0.1283 - val_accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1011 - accuracy: 0.9699 - val_loss: 0.1281 - val_accuracy: 0.9613\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0997 - accuracy: 0.9704 - val_loss: 0.1290 - val_accuracy: 0.9624\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0984 - accuracy: 0.9708 - val_loss: 0.1269 - val_accuracy: 0.9614\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0970 - accuracy: 0.9708 - val_loss: 0.1266 - val_accuracy: 0.9638\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0955 - accuracy: 0.9714 - val_loss: 0.1253 - val_accuracy: 0.9619\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0943 - accuracy: 0.9721 - val_loss: 0.1234 - val_accuracy: 0.9631\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0927 - accuracy: 0.9723 - val_loss: 0.1224 - val_accuracy: 0.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0916 - accuracy: 0.9728 - val_loss: 0.1268 - val_accuracy: 0.9627\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0903 - accuracy: 0.9732 - val_loss: 0.1270 - val_accuracy: 0.9624\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0891 - accuracy: 0.9737 - val_loss: 0.1226 - val_accuracy: 0.9638\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0876 - accuracy: 0.9740 - val_loss: 0.1216 - val_accuracy: 0.9637\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0866 - accuracy: 0.9739 - val_loss: 0.1223 - val_accuracy: 0.9622\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0855 - accuracy: 0.9748 - val_loss: 0.1213 - val_accuracy: 0.9642\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0841 - accuracy: 0.9755 - val_loss: 0.1223 - val_accuracy: 0.9633\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.1189 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0821 - accuracy: 0.9759 - val_loss: 0.1188 - val_accuracy: 0.9656\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0809 - accuracy: 0.9760 - val_loss: 0.1198 - val_accuracy: 0.9638\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0802 - accuracy: 0.9762 - val_loss: 0.1203 - val_accuracy: 0.9640\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0789 - accuracy: 0.9769 - val_loss: 0.1172 - val_accuracy: 0.9651\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0779 - accuracy: 0.9773 - val_loss: 0.1242 - val_accuracy: 0.9644\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0772 - accuracy: 0.9771 - val_loss: 0.1182 - val_accuracy: 0.9652\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.1234 - val_accuracy: 0.9637\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0749 - accuracy: 0.9779 - val_loss: 0.1228 - val_accuracy: 0.9642\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0742 - accuracy: 0.9784 - val_loss: 0.1176 - val_accuracy: 0.9654\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0732 - accuracy: 0.9786 - val_loss: 0.1183 - val_accuracy: 0.9652\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0725 - accuracy: 0.9783 - val_loss: 0.1171 - val_accuracy: 0.9651\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0714 - accuracy: 0.9789 - val_loss: 0.1212 - val_accuracy: 0.9644\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0704 - accuracy: 0.9794 - val_loss: 0.1157 - val_accuracy: 0.9673\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0697 - accuracy: 0.9798 - val_loss: 0.1168 - val_accuracy: 0.9656\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0689 - accuracy: 0.9793 - val_loss: 0.1174 - val_accuracy: 0.9656\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0677 - accuracy: 0.9802 - val_loss: 0.1193 - val_accuracy: 0.9641\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0674 - accuracy: 0.9801 - val_loss: 0.1198 - val_accuracy: 0.9650\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0664 - accuracy: 0.9805 - val_loss: 0.1163 - val_accuracy: 0.9652\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0656 - accuracy: 0.9808 - val_loss: 0.1164 - val_accuracy: 0.9644\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0647 - accuracy: 0.9815 - val_loss: 0.1147 - val_accuracy: 0.9662\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0639 - accuracy: 0.9817 - val_loss: 0.1173 - val_accuracy: 0.9654\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 0.1149 - val_accuracy: 0.9668\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0625 - accuracy: 0.9815 - val_loss: 0.1156 - val_accuracy: 0.9660\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0619 - accuracy: 0.9819 - val_loss: 0.1156 - val_accuracy: 0.9654\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0611 - accuracy: 0.9822 - val_loss: 0.1159 - val_accuracy: 0.9660\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0604 - accuracy: 0.9821 - val_loss: 0.1163 - val_accuracy: 0.9664\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 0.1236 - val_accuracy: 0.9645\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.1187 - val_accuracy: 0.9658\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0581 - accuracy: 0.9837 - val_loss: 0.1174 - val_accuracy: 0.9662\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0577 - accuracy: 0.9831 - val_loss: 0.1145 - val_accuracy: 0.9671\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0571 - accuracy: 0.9832 - val_loss: 0.1161 - val_accuracy: 0.9666\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0564 - accuracy: 0.9831 - val_loss: 0.1148 - val_accuracy: 0.9673\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0554 - accuracy: 0.9841 - val_loss: 0.1130 - val_accuracy: 0.9671\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 0.1154 - val_accuracy: 0.9667\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.1121 - val_accuracy: 0.9678\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.1167 - val_accuracy: 0.9670\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0535 - accuracy: 0.9842 - val_loss: 0.1170 - val_accuracy: 0.9668\n",
      "Total compute time to train model_5c was: 112.52 seconds\n",
      "Training Accuracy: 0.9842\n",
      "Test Accuracy: 0.9668\n",
      "Training Loss: 0.0535\n",
      "Test Loss: 0.1170\n"
     ]
    }
   ],
   "source": [
    "#Multilayer perceptron \n",
    "\n",
    "#model_5c uses three hidden layer\n",
    "model_5c = Sequential()\n",
    "model_5c.add(Dense(units=32, activation='relu', input_shape=(784,)))\n",
    "model_5c.add(Dense(units=32, activation='relu')) \n",
    "model_5c.add(Dense(units=32, activation='relu')) \n",
    "\n",
    "model_5c.add(Dense(units=10, activation='softmax')) \n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model_5c.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_5c_history = model_5c.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_5c was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_5c_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_5c_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_5c_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_5c_history.history['val_loss'][-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train matrix shape (60000, 28, 28, 1)\n",
      "Final Test matrix shape (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data again for CNN\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "# print the final input shape ready for training\n",
    "print(\"Final Train matrix shape\", X_train.shape)\n",
    "print(\"Final Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Investigating Effect of Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 47s 783us/step - loss: 0.9456 - accuracy: 0.6836 - val_loss: 0.4174 - val_accuracy: 0.8646\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 45s 746us/step - loss: 0.2532 - accuracy: 0.9220 - val_loss: 0.1694 - val_accuracy: 0.9487\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.1333 - accuracy: 0.9586 - val_loss: 0.1126 - val_accuracy: 0.9640\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 43s 715us/step - loss: 0.0915 - accuracy: 0.9711 - val_loss: 0.0701 - val_accuracy: 0.9782\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 43s 710us/step - loss: 0.0720 - accuracy: 0.9769 - val_loss: 0.0557 - val_accuracy: 0.9828\n",
      "Total compute time to train model_6a was: 222.13 seconds\n",
      "Training Accuracy: 0.9769\n",
      "Test Accuracy: 0.9828\n",
      "Training Loss: 0.0720\n",
      "Test Loss: 0.0557\n"
     ]
    }
   ],
   "source": [
    "#CNN \n",
    "\n",
    "#model_6a uses a learning rate of 0.001\n",
    "\n",
    "model_6a = Sequential()\n",
    "model_6a.add(Conv2D(filters = 32, kernel_size =(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_6a.add(MaxPooling2D((2, 2)))\n",
    "model_6a.add(Conv2D(filters = 64, kernel_size =(3, 3), activation='relu'))\n",
    "model_6a.add(MaxPooling2D((2, 2)))\n",
    "model_6a.add(Conv2D(filters = 64, kernel_size =(3, 3), activation='relu'))\n",
    "model_6a.add(Flatten())\n",
    "model_6a.add(Dense(64, activation='relu'))\n",
    "model_6a.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile model_6a\n",
    "rmsprop = optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "model_6a.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_6a_history = model_6a.fit(x=X_train, y=y_train, batch_size=64, epochs=5, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_6a was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_6a_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_6a_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_6a_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_6a_history.history['val_loss'][-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 42s 707us/step - loss: 2.0302 - accuracy: 0.4227 - val_loss: 1.3004 - val_accuracy: 0.6693\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 46s 762us/step - loss: 0.8559 - accuracy: 0.7491 - val_loss: 0.5903 - val_accuracy: 0.8168\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.5607 - accuracy: 0.8267 - val_loss: 0.4881 - val_accuracy: 0.8476\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 49s 817us/step - loss: 0.4804 - accuracy: 0.8520 - val_loss: 0.4280 - val_accuracy: 0.8670\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 44s 734us/step - loss: 0.4328 - accuracy: 0.8654 - val_loss: 0.3991 - val_accuracy: 0.8768\n",
      "Total compute time to train model_6b was: 233.13 seconds\n",
      "Training Accuracy: 0.8654\n",
      "Test Accuracy: 0.8768\n",
      "Training Loss: 0.4328\n",
      "Test Loss: 0.3991\n"
     ]
    }
   ],
   "source": [
    "#CNN \n",
    "\n",
    "#model_6b uses a learning rate of 0.0001\n",
    "\n",
    "model_6b = Sequential()\n",
    "model_6b.add(Conv2D(filters = 32, kernel_size =(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_6b.add(MaxPooling2D((2, 2)))\n",
    "model_6b.add(Conv2D(filters = 64, kernel_size =(3, 3), activation='relu'))\n",
    "model_6b.add(MaxPooling2D((2, 2)))\n",
    "model_6b.add(Conv2D(filters = 64, kernel_size =(3, 3), activation='relu'))\n",
    "model_6b.add(Flatten())\n",
    "model_6b.add(Dense(64, activation='relu'))\n",
    "model_6b.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile model_6b\n",
    "rmsprop = optimizers.RMSprop(learning_rate=0.0001, rho=0.9)\n",
    "model_6b.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_6b_history = model_6b.fit(x=X_train, y=y_train, batch_size=64, epochs=5, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_6b was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_6b_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_6b_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_6b_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_6b_history.history['val_loss'][-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 43s 712us/step - loss: 2.3150 - accuracy: 0.1104 - val_loss: 2.3018 - val_accuracy: 0.1028\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 44s 727us/step - loss: 2.3020 - accuracy: 0.1099 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 43s 710us/step - loss: 2.3023 - accuracy: 0.1106 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 44s 730us/step - loss: 2.3021 - accuracy: 0.1104 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 44s 729us/step - loss: 2.3022 - accuracy: 0.1101 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
      "Total compute time to train model_6c was: 217.17 seconds\n",
      "Training Accuracy: 0.1101\n",
      "Test Accuracy: 0.1135\n",
      "Training Loss: 2.3022\n",
      "Test Loss: 2.3020\n"
     ]
    }
   ],
   "source": [
    "#CNN \n",
    "\n",
    "#model_6c uses a learning rate of 0.01\n",
    "\n",
    "model_6c = Sequential()\n",
    "model_6c.add(Conv2D(filters = 32, kernel_size =(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_6c.add(MaxPooling2D((2, 2)))\n",
    "model_6c.add(Conv2D(filters = 64, kernel_size =(3, 3), activation='relu'))\n",
    "model_6c.add(MaxPooling2D((2, 2)))\n",
    "model_6c.add(Conv2D(filters = 64, kernel_size =(3, 3), activation='relu'))\n",
    "model_6c.add(Flatten())\n",
    "model_6c.add(Dense(64, activation='relu'))\n",
    "model_6c.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile model_6c\n",
    "rmsprop = optimizers.RMSprop(learning_rate=0.01, rho=0.9)\n",
    "model_6c.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_6c_history = model_6c.fit(x=X_train, y=y_train, batch_size=64, epochs=5, verbose=True, validation_data=(X_test, y_test))\n",
    "finish = time.time()\n",
    "\n",
    "#print report of accuracy, loss and run time \n",
    "print(f'Total compute time to train model_6c was: {finish-start:.2f} seconds')\n",
    "print(f\"Training Accuracy: {model_6c_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Test Accuracy: {model_6c_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {model_6c_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {model_6c_history.history['val_loss'][-1]:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
